{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 Welcome to the Connext docs! At Connext, our goal is to build the cross-chain routing and micropayment layer of the decentralized web. Connext sits on top of Ethereum, evm-compatible L2 blockchains, and other turing-complete chains, and enables instant, near free transfers that can be routed across chains and over liquidity in any asset . Most importantly, it does this without giving up the trust-minimization properties of the underlying chain. You can think of Connext as a shared standard for blockchains and other decentralized networks to communicate with each other about value. Where Do I Start? \u00b6 Anyone who is interacting with Connext needs to run a Connext node in some capacity. Connext nodes run the protocol, deploy channels to peers, and transfer value within those channels. We have two implementations of the node: The server-node , which uses docker to package up core logic and exposes http and gRPC interfaces. The browser-node , which is distributed via npm and exposes a typescript/javascript interface. You can also run the Connext node as an intermediary (we call this a routing node ), where you forward transfers between different channels. This way, peers can transfer to each other without needing channels directly to one other, but instead by \"hopping\" value across many different channels through the network. Routing nodes run server-node s with an automated module - a router - to forward transfers. If you're building a browser-based application, check out the browser-node quick start guide . If you're building a server application or backend/native infrastructure that runs on docker, check out the server-node quick start guide If you're building a protocol or network that leverages p2p micropayments, you will want to write custom transfer logic , integrate one or both of the two above nodes into user-facing code, and likely run a router to bootstrap the network. If you want to be a liquidity provider in the network, either to forward transfers or to bridge value across chains, you'll want to run a router . If you're still confused about where to begin, join us in our community chat ! We're very responsive and happy to point you to the right resources. :) What are State Channels? \u00b6 Connext is a network of state channels . The core concept behind a channel is very simple: Suppose you're paying your friend Bob for a metered service at the rate of \\$1 every minute. It would be silly to broadcast every transaction to the blockchain, you would incur lots of fees. At the same time, it also doesn't make sense to pay up front or pay at the end, as that would introduce new trust assumptions. Instead, what you can do is send your funds to a 2/2 multisig controlled by you and Bob. Then, rather than sending onchain transactions, you can send Bob ever updating signatures which give Bob the ability to withdraw up to a certain amount from the multisig. Because Bob can get his funds at any time using his unbreakable commitment from you, you complete a new payment to him every time you send a new signature. Connext extends this concept in a couple of ways ways: Updates within the channel can have any arbitrary conditionality to them. This means you could make your payments conditional upon Bob providing a proof of his work, or based on some real world event, or even based on the outcome of a chess game. More importantly: the above paradigm requires you to deploy a new multisig with each new person you transact with. Using the conditionality described above, Connext instead lets you use your channel with Bob to atomically interact with anyone that Bob also has a channel with. For instance, you pay Bob $1, who pays Charlie $0.9999 (Bob takes a microfee), who pays Danielle \\$0.9998 (Charlie takes a microfee). There's a lot more information available publicly on state channels, here are some great resources: State channels for babies Counterfactual for dummies EthHub","title":"Welcome"},{"location":"#welcome","text":"Welcome to the Connext docs! At Connext, our goal is to build the cross-chain routing and micropayment layer of the decentralized web. Connext sits on top of Ethereum, evm-compatible L2 blockchains, and other turing-complete chains, and enables instant, near free transfers that can be routed across chains and over liquidity in any asset . Most importantly, it does this without giving up the trust-minimization properties of the underlying chain. You can think of Connext as a shared standard for blockchains and other decentralized networks to communicate with each other about value.","title":"Welcome"},{"location":"#where-do-i-start","text":"Anyone who is interacting with Connext needs to run a Connext node in some capacity. Connext nodes run the protocol, deploy channels to peers, and transfer value within those channels. We have two implementations of the node: The server-node , which uses docker to package up core logic and exposes http and gRPC interfaces. The browser-node , which is distributed via npm and exposes a typescript/javascript interface. You can also run the Connext node as an intermediary (we call this a routing node ), where you forward transfers between different channels. This way, peers can transfer to each other without needing channels directly to one other, but instead by \"hopping\" value across many different channels through the network. Routing nodes run server-node s with an automated module - a router - to forward transfers. If you're building a browser-based application, check out the browser-node quick start guide . If you're building a server application or backend/native infrastructure that runs on docker, check out the server-node quick start guide If you're building a protocol or network that leverages p2p micropayments, you will want to write custom transfer logic , integrate one or both of the two above nodes into user-facing code, and likely run a router to bootstrap the network. If you want to be a liquidity provider in the network, either to forward transfers or to bridge value across chains, you'll want to run a router . If you're still confused about where to begin, join us in our community chat ! We're very responsive and happy to point you to the right resources. :)","title":"Where Do I Start?"},{"location":"#what-are-state-channels","text":"Connext is a network of state channels . The core concept behind a channel is very simple: Suppose you're paying your friend Bob for a metered service at the rate of \\$1 every minute. It would be silly to broadcast every transaction to the blockchain, you would incur lots of fees. At the same time, it also doesn't make sense to pay up front or pay at the end, as that would introduce new trust assumptions. Instead, what you can do is send your funds to a 2/2 multisig controlled by you and Bob. Then, rather than sending onchain transactions, you can send Bob ever updating signatures which give Bob the ability to withdraw up to a certain amount from the multisig. Because Bob can get his funds at any time using his unbreakable commitment from you, you complete a new payment to him every time you send a new signature. Connext extends this concept in a couple of ways ways: Updates within the channel can have any arbitrary conditionality to them. This means you could make your payments conditional upon Bob providing a proof of his work, or based on some real world event, or even based on the outcome of a chess game. More importantly: the above paradigm requires you to deploy a new multisig with each new person you transact with. Using the conditionality described above, Connext instead lets you use your channel with Bob to atomically interact with anyone that Bob also has a channel with. For instance, you pay Bob $1, who pays Charlie $0.9999 (Bob takes a microfee), who pays Danielle \\$0.9998 (Charlie takes a microfee). There's a lot more information available publicly on state channels, here are some great resources: State channels for babies Counterfactual for dummies EthHub","title":"What are State Channels?"},{"location":"changelog/","text":"Vector Changelog \u00b6 Next Release \u00b6 @connext/{types,utils,contracts,protocol,engine,browser-node}@0.0.6-beta.1, @connext/{server-node}@0.0.8 \u00b6 fix defundNonce in server node store expose nats 4221 by default support trio and contract testing across remote chains improve asset handling minor changes in transfer definitions and transfer registry @connext/{types,utils,contracts,protocol,engine,browser-node}@0.0.4 \u00b6 Fix webpack configs for browser node. @connext/{types,utils,contracts,protocol,engine,browser-node}@0.0.3-beta.5 \u00b6 add revert messages to LibIterableMapping . fix browser-node store getChannelStateByParticipants method. @connext/{types,utils,contracts,protocol,engine,browser-node}@0.0.3-beta.0 \u00b6 fix bug in onchain computation of channel address. simplify Proxy contract. @connext/vector-utils dependency fixes. migrate buidler to hardhat.","title":"Vector Changelog"},{"location":"changelog/#vector-changelog","text":"","title":"Vector Changelog"},{"location":"changelog/#next-release","text":"","title":"Next Release"},{"location":"changelog/#connexttypesutilscontractsprotocolenginebrowser-node006-beta1-connextserver-node008","text":"fix defundNonce in server node store expose nats 4221 by default support trio and contract testing across remote chains improve asset handling minor changes in transfer definitions and transfer registry","title":"@connext/{types,utils,contracts,protocol,engine,browser-node}@0.0.6-beta.1, @connext/{server-node}@0.0.8"},{"location":"changelog/#connexttypesutilscontractsprotocolenginebrowser-node004","text":"Fix webpack configs for browser node.","title":"@connext/{types,utils,contracts,protocol,engine,browser-node}@0.0.4"},{"location":"changelog/#connexttypesutilscontractsprotocolenginebrowser-node003-beta5","text":"add revert messages to LibIterableMapping . fix browser-node store getChannelStateByParticipants method.","title":"@connext/{types,utils,contracts,protocol,engine,browser-node}@0.0.3-beta.5"},{"location":"changelog/#connexttypesutilscontractsprotocolenginebrowser-node003-beta0","text":"fix bug in onchain computation of channel address. simplify Proxy contract. @connext/vector-utils dependency fixes. migrate buidler to hardhat.","title":"@connext/{types,utils,contracts,protocol,engine,browser-node}@0.0.3-beta.0"},{"location":"node/basics/","text":"Basics \u00b6 A Connext node is an implementation of the Connext protocols. Anyone who is using Connext in any way should most likely be running a node. Nodes take in the following: - Access to a user key, from which a ChannelSigner can be created. - etc. There are two primary node implementations available right now, both written in Typescript: - server-node - browser-node Server-Node vs. Browser-Node \u00b6 In general, nodes expose very similar interfaces and behave very similarly. There are a few notable differences, however: Server-Node Browser-Node Interface(s) gRPC and REST typescript Distribution Docker image npm Environment Variables Passed in via config-node.json file Set via .env or passed in on instantiation Key Management Takes in a mnemonic and supports creating multiple signers by passing in an index . See more below. Takes in a single ChannelSigner Server-Node Specific Functionality \u00b6 Using the Server Node JS Client \u00b6 The server-node's HTTP requests are wrapped into a JS client . This can be installed into a standalone Node.js program by installing the @connext/vector-utils package. Minimally, the client is instantiated like so (assuming a local setup similar to make start-node or make start-duet ): import { RestServerNodeService } from \"@connext/vector-utils\" ; import pino from \"pino\" ; const alice = await RestServerNodeService . connect ( \"http://localhost:8001\" , { 1337 : \"http://localhost:8545\" }, pino ()); The client has wrapper methods for the server-node 's REST interface, which implement the interface IServerNodeService . Note: because the browser-node exposes a TS interface directly, there is no need to do this in the browser. Indexed Engines \u00b6 In most cases, the server-node manages a single private key and signs all channel operations with this key. However, server-nodes also possess the ability to handle many different signers in the same stack concurrently. You can do this by specifying an index param in the connect method. This functionality is possible in the server-node by deriving private keys from the mnemonic in the server-node 's config ( more info ). By default, the server-node creates an engine at the index path \"0\" for convenience. Below is an example of creating a new Engine instance. The index param is an integer between 0 and 2147483647 (2^32): POST {{aliceUrl}}/node Content-Type: application/json { \"index\": 1234 } The response to this request contains a signerAddress and publicIdentifier . Additional calls to the server node must include the publicIdentifier to specify which engine to use.","title":"Basics"},{"location":"node/basics/#basics","text":"A Connext node is an implementation of the Connext protocols. Anyone who is using Connext in any way should most likely be running a node. Nodes take in the following: - Access to a user key, from which a ChannelSigner can be created. - etc. There are two primary node implementations available right now, both written in Typescript: - server-node - browser-node","title":"Basics"},{"location":"node/basics/#server-node-vs-browser-node","text":"In general, nodes expose very similar interfaces and behave very similarly. There are a few notable differences, however: Server-Node Browser-Node Interface(s) gRPC and REST typescript Distribution Docker image npm Environment Variables Passed in via config-node.json file Set via .env or passed in on instantiation Key Management Takes in a mnemonic and supports creating multiple signers by passing in an index . See more below. Takes in a single ChannelSigner","title":"Server-Node vs. Browser-Node"},{"location":"node/basics/#server-node-specific-functionality","text":"","title":"Server-Node Specific Functionality"},{"location":"node/basics/#using-the-server-node-js-client","text":"The server-node's HTTP requests are wrapped into a JS client . This can be installed into a standalone Node.js program by installing the @connext/vector-utils package. Minimally, the client is instantiated like so (assuming a local setup similar to make start-node or make start-duet ): import { RestServerNodeService } from \"@connext/vector-utils\" ; import pino from \"pino\" ; const alice = await RestServerNodeService . connect ( \"http://localhost:8001\" , { 1337 : \"http://localhost:8545\" }, pino ()); The client has wrapper methods for the server-node 's REST interface, which implement the interface IServerNodeService . Note: because the browser-node exposes a TS interface directly, there is no need to do this in the browser.","title":"Using the Server Node JS Client"},{"location":"node/basics/#indexed-engines","text":"In most cases, the server-node manages a single private key and signs all channel operations with this key. However, server-nodes also possess the ability to handle many different signers in the same stack concurrently. You can do this by specifying an index param in the connect method. This functionality is possible in the server-node by deriving private keys from the mnemonic in the server-node 's config ( more info ). By default, the server-node creates an engine at the index path \"0\" for convenience. Below is an example of creating a new Engine instance. The index param is an integer between 0 and 2147483647 (2^32): POST {{aliceUrl}}/node Content-Type: application/json { \"index\": 1234 } The response to this request contains a signerAddress and publicIdentifier . Additional calls to the server node must include the publicIdentifier to specify which engine to use.","title":"Indexed Engines"},{"location":"node/configure/","text":"Configuration and Deployment \u00b6 The node stack is configurable via the config-node.json file. Note that the duet and trio stacks are designed exclusively for development/testing so these are not configurable. There is an additional config-prod.json file that can apply to either the node or router but not both. The config-prod.json file contains your domain name and, because it's not tracked by git, it's a good place to put overrides for secret values like API keys. A prod-mode deployment using a domain name w https must be exposed on port 443, therefore only a single prod-mode stack can run on a given machine at a time. Node Configuration API \u00b6 config-node.json contains the default configuration for the node stack: make start-node . Any of these values can be overwritten by providing the same key with a new value to config-prod.json . Node Config Keys: adminToken (type: string ): Currently, this is only used during development to protect a few admin endpoints eg to reset the database between tests. If/when we add admin-only features in prod, they will only be accessible to those who provide the correct adminToken. chainAddresses (type: object ): Specifies the addresses of all relevant contracts, keyed by chainId . chainProviders (type: object ): Specifies the URL to use to connect to each chain's provider, keyed by chainId logLevel (type: string ): one of \"debug\" , \"info\" , \"warn\" , \"error\" to specify the maximum log level that will be printed. messagingUrl (type: string ): The url used to access the messaging service mnemonic (type: string ): Optional. If provided, the node will use this mnemonic. If not provided, the node will use a hard coded mnemonic with testnet funds in dev-mode (production=false). If not provided in prod, docker secrets will be used to manage the mnemonic; this is a much safer place to store a mnemonic that eg holds mainnet funds. port (type: number ): The port number on which the stack should be exposed to the outside world. Prod Configuration API \u00b6 Changes to config-prod.json aren't tracked by git so this is a good place to store secret API keys, etc. Be careful, changes to this file will be applied to both node & router stacks running on this machine. Prod Config Keys: awsAccessId (type: string ): An API KEY id that specifies credentials for a remote AWS S3 bucket for storing db backups awsAccessKey (type: string ): An API KEY secret that to authenticate on a remote AWS S3 bucket for storing db backups. domainName (type: string ): If provided, https will be auto-configured & the stack will be exposed on port 443. production (type: boolean ): Enables prod-mode if true. Implications of this flag: if false , ops will automatically build anything that isn't available locally before starting up a given stack. If true , nothing will be built locally. Instead, all images will be pulled from docker hub. if false , the global stack will start up 2 local testnet evm. Mnemonic handling is affected, see docs for the mnemonic key in node config. Single-Container Mode \u00b6 Using the start scripts in the Vector Makefile requires docker-compose. To run a server-node as a single container without docker-compose, do the following: Create a config file using the above instructions. Pull the Docker image from the repo: $ docker pull connextproject/vector_node Create a volume for the persisted database (can also use a bind-mounted file here): $ docker volume create vector_node_store Run the node container with the proper env vars (Note: Replace latest tag with a released version number in prod!): $ docker run --env VECTOR_CONFIG = \" $( cat node.config.json ) \" --env VECTOR_PROD = true --env VECTOR_SQLITE_FILE = \"/database/store.db\" -p \"8000:8000\" --mount type = volume,source = vector_node_store,destination = /database --name vector_node --rm connextproject/vector_node:latest ... $ curl http://localhost:8000/ping pong","title":"Configuration and Deployment"},{"location":"node/configure/#configuration-and-deployment","text":"The node stack is configurable via the config-node.json file. Note that the duet and trio stacks are designed exclusively for development/testing so these are not configurable. There is an additional config-prod.json file that can apply to either the node or router but not both. The config-prod.json file contains your domain name and, because it's not tracked by git, it's a good place to put overrides for secret values like API keys. A prod-mode deployment using a domain name w https must be exposed on port 443, therefore only a single prod-mode stack can run on a given machine at a time.","title":"Configuration and Deployment"},{"location":"node/configure/#node-configuration-api","text":"config-node.json contains the default configuration for the node stack: make start-node . Any of these values can be overwritten by providing the same key with a new value to config-prod.json . Node Config Keys: adminToken (type: string ): Currently, this is only used during development to protect a few admin endpoints eg to reset the database between tests. If/when we add admin-only features in prod, they will only be accessible to those who provide the correct adminToken. chainAddresses (type: object ): Specifies the addresses of all relevant contracts, keyed by chainId . chainProviders (type: object ): Specifies the URL to use to connect to each chain's provider, keyed by chainId logLevel (type: string ): one of \"debug\" , \"info\" , \"warn\" , \"error\" to specify the maximum log level that will be printed. messagingUrl (type: string ): The url used to access the messaging service mnemonic (type: string ): Optional. If provided, the node will use this mnemonic. If not provided, the node will use a hard coded mnemonic with testnet funds in dev-mode (production=false). If not provided in prod, docker secrets will be used to manage the mnemonic; this is a much safer place to store a mnemonic that eg holds mainnet funds. port (type: number ): The port number on which the stack should be exposed to the outside world.","title":"Node Configuration API"},{"location":"node/configure/#prod-configuration-api","text":"Changes to config-prod.json aren't tracked by git so this is a good place to store secret API keys, etc. Be careful, changes to this file will be applied to both node & router stacks running on this machine. Prod Config Keys: awsAccessId (type: string ): An API KEY id that specifies credentials for a remote AWS S3 bucket for storing db backups awsAccessKey (type: string ): An API KEY secret that to authenticate on a remote AWS S3 bucket for storing db backups. domainName (type: string ): If provided, https will be auto-configured & the stack will be exposed on port 443. production (type: boolean ): Enables prod-mode if true. Implications of this flag: if false , ops will automatically build anything that isn't available locally before starting up a given stack. If true , nothing will be built locally. Instead, all images will be pulled from docker hub. if false , the global stack will start up 2 local testnet evm. Mnemonic handling is affected, see docs for the mnemonic key in node config.","title":"Prod Configuration API"},{"location":"node/configure/#single-container-mode","text":"Using the start scripts in the Vector Makefile requires docker-compose. To run a server-node as a single container without docker-compose, do the following: Create a config file using the above instructions. Pull the Docker image from the repo: $ docker pull connextproject/vector_node Create a volume for the persisted database (can also use a bind-mounted file here): $ docker volume create vector_node_store Run the node container with the proper env vars (Note: Replace latest tag with a released version number in prod!): $ docker run --env VECTOR_CONFIG = \" $( cat node.config.json ) \" --env VECTOR_PROD = true --env VECTOR_SQLITE_FILE = \"/database/store.db\" -p \"8000:8000\" --mount type = volume,source = vector_node_store,destination = /database --name vector_node --rm connextproject/vector_node:latest ... $ curl http://localhost:8000/ping pong","title":"Single-Container Mode"},{"location":"node/events/","text":"Events \u00b6 To subscribe to the server-node 's event emitter, the JS client uses webhooks. A program that wants to listen for the server-node 's events needs to implement an HTTP server that can accept POST requests which the server-node POSTs to when events are generated. The JS client uses a mapping of EVTs which should be posted to when the HTTP request is received to allow for more powerful filtering capabilities behind an easy to use interface. A full example can be found in the implementation of the router module , here are relevant snippets: import { Evt } from \"evt\" ; import fastify from \"fastify\" ; import { RestServerNodeService } from \"@connext/vector-utils\" ; import { ConditionalTransferCreatedPayload , ConditionalTransferResolvedPayload , EngineEvents , } from \"@connext/vector-types\" ; // using fastify as the web server const server = fastify (); // configure event subscriptions const serverBase = `http://localhost:3000` ; // this server // callback paths const conditionalTransferCreatedPath = \"/conditional-transfer-created\" ; const conditionalTransferResolvedPath = \"/conditional-transfer-resolved\" ; const evts = { [ EngineEvents . CONDITIONAL_TRANSFER_CREATED ] : { evt : Evt.create < ConditionalTransferCreatedPayload > (), url : ` ${ routerBase }${ conditionalTransferCreatedPath } ` , }, [ EngineEvents . CONDITIONAL_TRANSFER_RESOLVED ] : { evt : Evt.create < ConditionalTransferResolvedPayload > (), url : ` ${ routerBase }${ conditionalTransferResolvedPath } ` , }, [ EngineEvents . SETUP ] : {}, [ EngineEvents . WITHDRAWAL_CREATED ] : {}, [ EngineEvents . WITHDRAWAL_RESOLVED ] : {}, [ EngineEvents . WITHDRAWAL_RECONCILED ] : {}, [ EngineEvents . DEPOSIT_RECONCILED ] : {}, }; const logger = pino (); let node : RestServerNodeService | undefined ; server . addHook ( \"onReady\" , async () => { // asynchronously connect to server node node = await RestServerNodeService . connect ( \"http://localhost:8001\" , { 1337 : \"http://localhost:8545\" }, logger . child ({ module : \"RestServerNodeService\" }), // namespace logs by module evts , // event subscription config ); }); // endpoints to receive server-node events server . post ( conditionalTransferCreatedPath , async ( request , response ) => { // post to the EVT that we pass into the server-node client evts [ EngineEvents . CONDITIONAL_TRANSFER_CREATED ]. post ( request . body as ConditionalTransferCreatedPayload ); return response . status ( 200 ). send ({ message : \"success\" }); }); server . post ( conditionalTransferResolvedPath , async ( request , response ) => { evts [ EngineEvents . CONDITIONAL_TRANSFER_RESOLVED ]. post ( request . body as ConditionalTransferResolvedPayload ); return response . status ( 200 ). send ({ message : \"success\" }); }); await node . on ( EngineEvents . CONDITIONAL_TRANSFER_CREATED , async data => { console . log ( `Received conditional transfer: ${ JSON . stringify ( data ) } ` ); }, data => data . transfer . initiator === \"indraABCD\" , // can filter on the data here );","title":"Events"},{"location":"node/events/#events","text":"To subscribe to the server-node 's event emitter, the JS client uses webhooks. A program that wants to listen for the server-node 's events needs to implement an HTTP server that can accept POST requests which the server-node POSTs to when events are generated. The JS client uses a mapping of EVTs which should be posted to when the HTTP request is received to allow for more powerful filtering capabilities behind an easy to use interface. A full example can be found in the implementation of the router module , here are relevant snippets: import { Evt } from \"evt\" ; import fastify from \"fastify\" ; import { RestServerNodeService } from \"@connext/vector-utils\" ; import { ConditionalTransferCreatedPayload , ConditionalTransferResolvedPayload , EngineEvents , } from \"@connext/vector-types\" ; // using fastify as the web server const server = fastify (); // configure event subscriptions const serverBase = `http://localhost:3000` ; // this server // callback paths const conditionalTransferCreatedPath = \"/conditional-transfer-created\" ; const conditionalTransferResolvedPath = \"/conditional-transfer-resolved\" ; const evts = { [ EngineEvents . CONDITIONAL_TRANSFER_CREATED ] : { evt : Evt.create < ConditionalTransferCreatedPayload > (), url : ` ${ routerBase }${ conditionalTransferCreatedPath } ` , }, [ EngineEvents . CONDITIONAL_TRANSFER_RESOLVED ] : { evt : Evt.create < ConditionalTransferResolvedPayload > (), url : ` ${ routerBase }${ conditionalTransferResolvedPath } ` , }, [ EngineEvents . SETUP ] : {}, [ EngineEvents . WITHDRAWAL_CREATED ] : {}, [ EngineEvents . WITHDRAWAL_RESOLVED ] : {}, [ EngineEvents . WITHDRAWAL_RECONCILED ] : {}, [ EngineEvents . DEPOSIT_RECONCILED ] : {}, }; const logger = pino (); let node : RestServerNodeService | undefined ; server . addHook ( \"onReady\" , async () => { // asynchronously connect to server node node = await RestServerNodeService . connect ( \"http://localhost:8001\" , { 1337 : \"http://localhost:8545\" }, logger . child ({ module : \"RestServerNodeService\" }), // namespace logs by module evts , // event subscription config ); }); // endpoints to receive server-node events server . post ( conditionalTransferCreatedPath , async ( request , response ) => { // post to the EVT that we pass into the server-node client evts [ EngineEvents . CONDITIONAL_TRANSFER_CREATED ]. post ( request . body as ConditionalTransferCreatedPayload ); return response . status ( 200 ). send ({ message : \"success\" }); }); server . post ( conditionalTransferResolvedPath , async ( request , response ) => { evts [ EngineEvents . CONDITIONAL_TRANSFER_RESOLVED ]. post ( request . body as ConditionalTransferResolvedPayload ); return response . status ( 200 ). send ({ message : \"success\" }); }); await node . on ( EngineEvents . CONDITIONAL_TRANSFER_CREATED , async data => { console . log ( `Received conditional transfer: ${ JSON . stringify ( data ) } ` ); }, data => data . transfer . initiator === \"indraABCD\" , // can filter on the data here );","title":"Events"},{"location":"node/transfers/","text":"Transfers \u00b6 A transfer is the primary mechanism by which a Connext channel is updated. Transfers have a fixed lifecycle: Alice creates a conditional transfer with Bob by calling conditionalTransfer() . The function takes in details around the value to be transferred ( amount , assetId , recipient ), as well as a transferDefinition and a details object (which is the initial state of the transfer). Doing this locks up Alice's funds corresponding to the amount above, making it so that they can only be unlocked by meeting the conditions specified within the transferDefinition . Bob calls resolveTransfer() which takes in a globally unique transferId associated with the above transfer, as well as a transferResolver , which is an object containing data needed to unlock the transfer. Transfer Definitions \u00b6 Transfer definitions specify the logic by which value locked in a transfer can be resolved into an updated set of balances. The ability to specify different transferDefinitions when creating a conditional transfer is what makes sending value using Connext programmable! To remove the need to write custom offchain code when adding support for new types of conditional transfers, we implement transferDefinition s as singleton Solidity contracts and pass in their deployed contract address when creating a conditional transfer. Transfer definitions always implement a standard interface: Transfer definition interface interface ITransferDefinition { // Validates the initial state of the transfer. // Called by validator.ts during `create` updates. function create ( bytes calldata encodedBalance , bytes calldata ) external view returns ( bool ); // Performs a state transition to resolve a transfer and returns final balances. // Called by validator.ts during `resolve` updates. function resolve ( bytes calldata encodedBalance , bytes calldata , bytes calldata ) external view returns ( Balance memory ); // Should also have the following properties // string name // string stateEncoding // string resolverEncoding // These properties are included on the transfer specifically // to make it easier for implementers to add new transfers by // only include a `.sol` file function getRegistryInformation () external view returns ( RegisteredTransfer memory ); } Here is an example transfer definition for a HashlockTransfer , i.e. a transfer which unlocks if the receiver provides a correct preImage that hashes to the same value as the lockHash provided on creation. Creating a Transfer \u00b6 You can create a transfer by calling the conditionalTransfer() method. TS const result = await node . conditionalTransfer ({ type : \"HashlockTransfer\" , channelAddress : \"0xABC123...\" , amount : \"1000000000000000\" , // 0.01 ETH assetId : \"0x0000000000000000000000000000000000000000\" , details : { lockHash : \"0xlockHash...\" , expiry : \"0\" }, recipient : \"indra123ABC...\" , meta : { hello : \"world\" } }); HTTP ############## ### Create Transfer ETH POST {{nodeUrl}}/transfers/create Content-Type: application/json { \"type\": \"HashlockTransfer\", \"channelAddress\": \"0xABC123...\", \"amount\": \"1000000000000000\", # 0.01 ETH \"assetId\": \"0x0000000000000000000000000000000000000000\", \"details\": { \"lockHash\": \"0xlockHash...\", \"expiry\": \"0\" }, \"recipient\": \"indra123ABC...\", \"meta\": { \"hello\": \"world\" } } The type field above can be EITHER a raw transferDefinition address, OR one of several default transfer names that we support. The details field must match the TransferState struct in the transferDefinition solidity contract: // Example from Hashlock Transfer struct TransferState { bytes32 lockHash ; uint256 expiry ; // If 0, then no timelock is enforced } Resolving a Transfer \u00b6 As a receiver, you can learn about an incoming transfer by listening for the CONDITIONAL_TRANSFER_CREATED event. TS await node . on ( EngineEvents . CONDITIONAL_TRANSFER_CREATED , async data => { console . log ( `Received conditional transfer: ${ JSON . stringify ( data ) } ` ); }, data => data . transfer . initiator === \"indraABCD\" , // can filter on the data here ); HTTP ## TODO Then, you can resolve (i.e. unlock) the transfer by calling the resolveCondition() function, passing in the data.transferId that you caught from the above event. TS const result = await node . resolveTransfer ({ channelAddress : \"0xABC123...\" , transferId : \"0xtransferId...\" , transferResolver : { preImage : \"0xpreimage...\" // For hashlock transfer } }); HTTP ############## ### Resolve Transfer POST {{nodeUrl}}/transfers/resolve Content-Type: application/json { \"channelAddress\": \"0xABC123...\", \"transferId\": \"0xtransferId...\", \"transferResolver\": { \"preImage\": \"0xpreimage...\" # For hashlock transfer } } Similar to the conditionalTransfer details field, the transferResolver must exactly match the TransferResolver struct from the transferDefinition contract: struct TransferResolver { bytes32 preImage ; } Transfers Across Chains and Assets \u00b6 Transfers in Connext are routed over one (eventually many) intermediary routers. Routers are Connext server-nodes that are running automated software to forward transfers across multiple channels. If the router that you're transferring over supports it , you can make transfers that swap across chains/assets while in-flight. In other words, a sender can send a transfer in $DAI on Ethereum, where the receiver receives $MATIC on Matic. To do this, specify the recipient asset and chainId as part of the transfer creation: TS const result = await node . conditionalTransfer ({ type : \"HashlockTransfer\" , channelAddress : \"0xABC123...\" , amount : \"1000000000000000\" , // 0.01 ETH assetId : \"0x0000000000000000000000000000000000000000\" , details : { lockHash : \"0xlockHash...\" , expiry : \"0\" }, recipient : \"indra123ABC...\" , recipientChainId : 137 , // Matic chainId // Recipient assetId is relative to recipient chain. 0x0 on Matic chain is $MATIC recipientAssetId : \"0x0000000000000000000000000000000000000000\" }); HTTP ############## ### Create Transfer ETH POST {{nodeUrl}}/transfers/create Content-Type: application/json { \"type\": \"HashlockTransfer\", \"channelAddress\": \"0xABC123...\", \"amount\": \"1000000000000000\", # 0.01 ETH \"assetId\": \"0x0000000000000000000000000000000000000000\", \"details\": { \"lockHash\": \"0xlockHash...\", \"expiry\": \"0\" }, \"recipient\": \"indra123ABC...\", recipientChainId: 137, // Matic chainId // Recipient assetId is relative to recipient chain. 0x0 on Matic chain is $MATIC recipientAssetId: \"0x0000000000000000000000000000000000000000\" } If recipientChainId or recipientAssetId are not provided, then the transfer will default to assuming it needs to be sent with the sender's chainId and the passed in assetId param respectively. Custom Transfer Logic \u00b6 One of the best things about a generalized system like Connext is the ability to specify your own custom conditional transfer logic. This lets you build new protocols and ecosystems on top of Connext that leverage our networked state channels in different ways. Adding support for a custom conditional transfer is pretty simple! There are three core steps to doing this: Design the conditional transfer and write the transferDefinition solidity contract. Submit the new transferDefinition for review so that it can be added to our growing global registry of transfer types. Call the new transfer with the right params in your offchain code. Writing the Transfer Definition Contract \u00b6 The only hard requirement for a Transfer Definition is that it adhere's to the interface defined above . The general pattern for doing this is to set up some initial condition when creating the transfer, and then checking to see if that condition is met before updating balances. Note In general, you don't need to be too concerned about the logistics of disputing onchain when writing a transfer. all onchain dispute logic (and the protocols that back this security) are pretty abstracted from the process of designing transfers. First, you should determine what goes into your TransferState and TransferResolver structs. We allow for metadata to be passed as part of a transfer separately, so the only fields in these structs should be those that are validated or manipulated directly as part of the transfer logic. Be sure to write ABIEncoderV2 encodings for both of these structs as defined in the interface. Warning To minimize time spent debugging Solidity, we strongly recommend you keep these structs and the core logic as simple as possible . Next, write the create() function. A good strategy is to work your way down the TransferState struct and validate each param. The create() function is called when calling conditionalTransfer() and is only place where the object passed in to details is actually validated. So it's useful to do all the param validation you can here. E.g. check to see if inputs are zeroes/empty bytes, etc. Lastly, write the resolve() function. The goal of the resolve() function, is to take in the initial TransferState , initial balance, and the passed in resolver to output a final balance. First, you should param validate all of the parts of the TransferResolver (you dont need to re-validate the TransferState ). Then you should check to see if the passed in resolver meets some conditions set up against the initial TransferState - if it does, you should update the balances and return them. If not, then you should either throw an error (i.e. fail a require() ) or just return the balance with no changes. Tip In some cases, we allow the transfer to be cooperatively cancelled by explicitly passing in an empty resolver. That way, there's a way to exit the transfer offchain if something goes wrong without needing to initiate an onchain dispute. Submitting the Definition to our Registry \u00b6 We deploy and maintain a global onchain registry of approved transferDefinition s. This makes it possible for routers in the network to safely forward transfer operations without needing to inspect the packets themselves, instead only needing to validate the definition addresses. We're working on a structured RFC process for supporting new transfer standards. For now, we recommend that you reach out to us directly so that we can manually audit your code and add it to the registry. Calling the New Transfer Logic \u00b6 After you have written the new transferDef, deployed it, and submitted it to us for review, the next step is to call it from your offchain code. Doing this works exactly the same way as described in the creating a transfer and resolving a transfer sections above. Plug in your deployed transferDefinition address in the type field, and then pass in the TransferState in details . Then, when resolving, pass in the TransferResolver in the transferResolver field.","title":"Transfers"},{"location":"node/transfers/#transfers","text":"A transfer is the primary mechanism by which a Connext channel is updated. Transfers have a fixed lifecycle: Alice creates a conditional transfer with Bob by calling conditionalTransfer() . The function takes in details around the value to be transferred ( amount , assetId , recipient ), as well as a transferDefinition and a details object (which is the initial state of the transfer). Doing this locks up Alice's funds corresponding to the amount above, making it so that they can only be unlocked by meeting the conditions specified within the transferDefinition . Bob calls resolveTransfer() which takes in a globally unique transferId associated with the above transfer, as well as a transferResolver , which is an object containing data needed to unlock the transfer.","title":"Transfers"},{"location":"node/transfers/#transfer-definitions","text":"Transfer definitions specify the logic by which value locked in a transfer can be resolved into an updated set of balances. The ability to specify different transferDefinitions when creating a conditional transfer is what makes sending value using Connext programmable! To remove the need to write custom offchain code when adding support for new types of conditional transfers, we implement transferDefinition s as singleton Solidity contracts and pass in their deployed contract address when creating a conditional transfer. Transfer definitions always implement a standard interface: Transfer definition interface interface ITransferDefinition { // Validates the initial state of the transfer. // Called by validator.ts during `create` updates. function create ( bytes calldata encodedBalance , bytes calldata ) external view returns ( bool ); // Performs a state transition to resolve a transfer and returns final balances. // Called by validator.ts during `resolve` updates. function resolve ( bytes calldata encodedBalance , bytes calldata , bytes calldata ) external view returns ( Balance memory ); // Should also have the following properties // string name // string stateEncoding // string resolverEncoding // These properties are included on the transfer specifically // to make it easier for implementers to add new transfers by // only include a `.sol` file function getRegistryInformation () external view returns ( RegisteredTransfer memory ); } Here is an example transfer definition for a HashlockTransfer , i.e. a transfer which unlocks if the receiver provides a correct preImage that hashes to the same value as the lockHash provided on creation.","title":"Transfer Definitions"},{"location":"node/transfers/#creating-a-transfer","text":"You can create a transfer by calling the conditionalTransfer() method. TS const result = await node . conditionalTransfer ({ type : \"HashlockTransfer\" , channelAddress : \"0xABC123...\" , amount : \"1000000000000000\" , // 0.01 ETH assetId : \"0x0000000000000000000000000000000000000000\" , details : { lockHash : \"0xlockHash...\" , expiry : \"0\" }, recipient : \"indra123ABC...\" , meta : { hello : \"world\" } }); HTTP ############## ### Create Transfer ETH POST {{nodeUrl}}/transfers/create Content-Type: application/json { \"type\": \"HashlockTransfer\", \"channelAddress\": \"0xABC123...\", \"amount\": \"1000000000000000\", # 0.01 ETH \"assetId\": \"0x0000000000000000000000000000000000000000\", \"details\": { \"lockHash\": \"0xlockHash...\", \"expiry\": \"0\" }, \"recipient\": \"indra123ABC...\", \"meta\": { \"hello\": \"world\" } } The type field above can be EITHER a raw transferDefinition address, OR one of several default transfer names that we support. The details field must match the TransferState struct in the transferDefinition solidity contract: // Example from Hashlock Transfer struct TransferState { bytes32 lockHash ; uint256 expiry ; // If 0, then no timelock is enforced }","title":"Creating a Transfer"},{"location":"node/transfers/#resolving-a-transfer","text":"As a receiver, you can learn about an incoming transfer by listening for the CONDITIONAL_TRANSFER_CREATED event. TS await node . on ( EngineEvents . CONDITIONAL_TRANSFER_CREATED , async data => { console . log ( `Received conditional transfer: ${ JSON . stringify ( data ) } ` ); }, data => data . transfer . initiator === \"indraABCD\" , // can filter on the data here ); HTTP ## TODO Then, you can resolve (i.e. unlock) the transfer by calling the resolveCondition() function, passing in the data.transferId that you caught from the above event. TS const result = await node . resolveTransfer ({ channelAddress : \"0xABC123...\" , transferId : \"0xtransferId...\" , transferResolver : { preImage : \"0xpreimage...\" // For hashlock transfer } }); HTTP ############## ### Resolve Transfer POST {{nodeUrl}}/transfers/resolve Content-Type: application/json { \"channelAddress\": \"0xABC123...\", \"transferId\": \"0xtransferId...\", \"transferResolver\": { \"preImage\": \"0xpreimage...\" # For hashlock transfer } } Similar to the conditionalTransfer details field, the transferResolver must exactly match the TransferResolver struct from the transferDefinition contract: struct TransferResolver { bytes32 preImage ; }","title":"Resolving a Transfer"},{"location":"node/transfers/#transfers-across-chains-and-assets","text":"Transfers in Connext are routed over one (eventually many) intermediary routers. Routers are Connext server-nodes that are running automated software to forward transfers across multiple channels. If the router that you're transferring over supports it , you can make transfers that swap across chains/assets while in-flight. In other words, a sender can send a transfer in $DAI on Ethereum, where the receiver receives $MATIC on Matic. To do this, specify the recipient asset and chainId as part of the transfer creation: TS const result = await node . conditionalTransfer ({ type : \"HashlockTransfer\" , channelAddress : \"0xABC123...\" , amount : \"1000000000000000\" , // 0.01 ETH assetId : \"0x0000000000000000000000000000000000000000\" , details : { lockHash : \"0xlockHash...\" , expiry : \"0\" }, recipient : \"indra123ABC...\" , recipientChainId : 137 , // Matic chainId // Recipient assetId is relative to recipient chain. 0x0 on Matic chain is $MATIC recipientAssetId : \"0x0000000000000000000000000000000000000000\" }); HTTP ############## ### Create Transfer ETH POST {{nodeUrl}}/transfers/create Content-Type: application/json { \"type\": \"HashlockTransfer\", \"channelAddress\": \"0xABC123...\", \"amount\": \"1000000000000000\", # 0.01 ETH \"assetId\": \"0x0000000000000000000000000000000000000000\", \"details\": { \"lockHash\": \"0xlockHash...\", \"expiry\": \"0\" }, \"recipient\": \"indra123ABC...\", recipientChainId: 137, // Matic chainId // Recipient assetId is relative to recipient chain. 0x0 on Matic chain is $MATIC recipientAssetId: \"0x0000000000000000000000000000000000000000\" } If recipientChainId or recipientAssetId are not provided, then the transfer will default to assuming it needs to be sent with the sender's chainId and the passed in assetId param respectively.","title":"Transfers Across Chains and Assets"},{"location":"node/transfers/#custom-transfer-logic","text":"One of the best things about a generalized system like Connext is the ability to specify your own custom conditional transfer logic. This lets you build new protocols and ecosystems on top of Connext that leverage our networked state channels in different ways. Adding support for a custom conditional transfer is pretty simple! There are three core steps to doing this: Design the conditional transfer and write the transferDefinition solidity contract. Submit the new transferDefinition for review so that it can be added to our growing global registry of transfer types. Call the new transfer with the right params in your offchain code.","title":"Custom Transfer Logic"},{"location":"node/transfers/#writing-the-transfer-definition-contract","text":"The only hard requirement for a Transfer Definition is that it adhere's to the interface defined above . The general pattern for doing this is to set up some initial condition when creating the transfer, and then checking to see if that condition is met before updating balances. Note In general, you don't need to be too concerned about the logistics of disputing onchain when writing a transfer. all onchain dispute logic (and the protocols that back this security) are pretty abstracted from the process of designing transfers. First, you should determine what goes into your TransferState and TransferResolver structs. We allow for metadata to be passed as part of a transfer separately, so the only fields in these structs should be those that are validated or manipulated directly as part of the transfer logic. Be sure to write ABIEncoderV2 encodings for both of these structs as defined in the interface. Warning To minimize time spent debugging Solidity, we strongly recommend you keep these structs and the core logic as simple as possible . Next, write the create() function. A good strategy is to work your way down the TransferState struct and validate each param. The create() function is called when calling conditionalTransfer() and is only place where the object passed in to details is actually validated. So it's useful to do all the param validation you can here. E.g. check to see if inputs are zeroes/empty bytes, etc. Lastly, write the resolve() function. The goal of the resolve() function, is to take in the initial TransferState , initial balance, and the passed in resolver to output a final balance. First, you should param validate all of the parts of the TransferResolver (you dont need to re-validate the TransferState ). Then you should check to see if the passed in resolver meets some conditions set up against the initial TransferState - if it does, you should update the balances and return them. If not, then you should either throw an error (i.e. fail a require() ) or just return the balance with no changes. Tip In some cases, we allow the transfer to be cooperatively cancelled by explicitly passing in an empty resolver. That way, there's a way to exit the transfer offchain if something goes wrong without needing to initiate an onchain dispute.","title":"Writing the Transfer Definition Contract"},{"location":"node/transfers/#submitting-the-definition-to-our-registry","text":"We deploy and maintain a global onchain registry of approved transferDefinition s. This makes it possible for routers in the network to safely forward transfer operations without needing to inspect the packets themselves, instead only needing to validate the definition addresses. We're working on a structured RFC process for supporting new transfer standards. For now, we recommend that you reach out to us directly so that we can manually audit your code and add it to the registry.","title":"Submitting the Definition to our Registry"},{"location":"node/transfers/#calling-the-new-transfer-logic","text":"After you have written the new transferDef, deployed it, and submitted it to us for review, the next step is to call it from your offchain code. Doing this works exactly the same way as described in the creating a transfer and resolving a transfer sections above. Plug in your deployed transferDefinition address in the type field, and then pass in the TransferState in details . Then, when resolving, pass in the TransferResolver in the transferResolver field.","title":"Calling the New Transfer Logic"},{"location":"quickStart/browserNode/","text":"Browser Node Quick Start \u00b6 This quick start will guide you through getting to a simple e2e transfer flow running between two peers running browser nodes that runs through an intermediary routing node. We assume you're starting with an existing JS application that runs in the browser. Spinning Up a Router Locally \u00b6 Prerequisites: make : Probably already installed, otherwise install w brew install make or apt install make or similar. jq : Probably not installed yet, install w brew install jq or apt install jq or similar. docker : sadly, Docker is kinda annoying to install. See website for instructions. First, clone the repo: git clone git@github.com:connext/vector.git cd vector Then, run: make start-router The above command will spin up a routing node in dev-mode along with some local services for messaging and auth. It will also create two local blockchains (at chainIds 1337 and 1338 respectively) and then will deploy the Connext contracts to those chains. Installation and Instantiation \u00b6 You can install the browser-node via npm : npm i @connext/vector-browser-node --save You'll also probably want the vector-utils package. npm i @connext/vector-utils --save Instantiating the node takes in the following constructor params: chainProviders : A provider URL for whatever chain(s) you want to connect to. E.g. Infura, Geth node in VPC, etc. Indexed by chainId . chainAddresses : An object containing Connext contract addresses also indexed by chainId . signer : A ChannelSigner, which can be created using the vector-utils package and a private key. messagingUrl : Local or remote URL access to a messaging service. In prod-mode, this is automatically defaulted to a global service. logger : A pino logger.","title":"Browser Node Quick Start"},{"location":"quickStart/browserNode/#browser-node-quick-start","text":"This quick start will guide you through getting to a simple e2e transfer flow running between two peers running browser nodes that runs through an intermediary routing node. We assume you're starting with an existing JS application that runs in the browser.","title":"Browser Node Quick Start"},{"location":"quickStart/browserNode/#spinning-up-a-router-locally","text":"Prerequisites: make : Probably already installed, otherwise install w brew install make or apt install make or similar. jq : Probably not installed yet, install w brew install jq or apt install jq or similar. docker : sadly, Docker is kinda annoying to install. See website for instructions. First, clone the repo: git clone git@github.com:connext/vector.git cd vector Then, run: make start-router The above command will spin up a routing node in dev-mode along with some local services for messaging and auth. It will also create two local blockchains (at chainIds 1337 and 1338 respectively) and then will deploy the Connext contracts to those chains.","title":"Spinning Up a Router Locally"},{"location":"quickStart/browserNode/#installation-and-instantiation","text":"You can install the browser-node via npm : npm i @connext/vector-browser-node --save You'll also probably want the vector-utils package. npm i @connext/vector-utils --save Instantiating the node takes in the following constructor params: chainProviders : A provider URL for whatever chain(s) you want to connect to. E.g. Infura, Geth node in VPC, etc. Indexed by chainId . chainAddresses : An object containing Connext contract addresses also indexed by chainId . signer : A ChannelSigner, which can be created using the vector-utils package and a private key. messagingUrl : Local or remote URL access to a messaging service. In prod-mode, this is automatically defaulted to a global service. logger : A pino logger.","title":"Installation and Instantiation"},{"location":"quickStart/serverNode/","text":"Server Node Quick Start \u00b6 This quick start will guide you through getting to a simple e2e transfer flow between two peers running server-nodes (Carol, Dave) that is routed through one intermediary routing node (Roger). Spinning Up the Stack Locally \u00b6 Prerequisites: make : Probably already installed, otherwise install w brew install make or apt install make or similar. jq : Probably not installed yet, install w brew install jq or apt install jq or similar. docker : sadly, Docker is kinda annoying to install. See website for instructions. First, clone the repo: git clone git@github.com:connext/vector.git cd vector Then, run: make start-trio The above command will spin up three server-nodes, one with an attached router in dev-mode. Note that in dev-mode, chain and db data will not be persisted between restarts. To run in prod mode, you can spin up a routing node with make start-router and non-routing server-nodes with make start-node . We have a guide on prod-mode deployments and configuration coming soon! Creating a Channel \u00b6 Once you have the above trio set up, you can interact with your nodes via a REST interface. We've documented example requests in the server-node module. If you're developing with VSCode, there are several REST client plugins available in the marketplace that you can use to make these queries directly from the examples . First, set up your nodes (in 0_config ) on the servers to register signers and create the engines. ### Node -> Carol POST {{carolUrl}}/node Content-Type: application/json { \"index\": 0 } ### Node -> Dave POST {{daveUrl}}/node Content-Type: application/json { \"index\": 0 } Then, set up your channels from Carol -> Roger and Roger -> Carol (in 1_Setup ). Note aliceUrl is the internal URL that Carol has access to on the Docker network. In these examples, Carol and Dave are requesting Roger to set up the channel with them so that they can be the \"Bob\" within the channel, which lets them deposit by transferrring directly into the channel address.: ### Carol -> Node POST {{carolUrl}}/setup Content-Type: application/json { \"counterpartyIdentifier\": \"{{rogerPublicIdentifier}}\", \"publicIdentifier\": \"{{carolPublicIdentifier}}\", \"chainId\": \"{{chainId}}\", \"timeout\": \"36000\" } ### Dave -> Node POST {{daveUrl}}/setup Content-Type: application/json { \"counterpartyIdentifier\": \"{{rogerPublicIdentifier}}\", \"publicIdentifier\": \"{{davePublicIdentifier}}\", \"chainId\": \"{{chainId}}\", \"timeout\": \"36000\" } Depositing Into a Channel \u00b6 Then, send an Eth deposit to Carol's channel onchain. This can be done by connecting Metamask to your local EVM at http://localhost:8545 and sending a transfer directly to the channelAddress , at any time, regardless of either channel participant's liveness status. A convenient way to do this using HTTP JSON-RPC calls is with a POST request: # Send a transaction to {{channelAddress}} for 100000000000000000 Wei POST http://localhost:8545 Content-Type: application/json { \"jsonrpc\":\"2.0\", \"method\":\"eth_sendTransaction\", \"params\":[{ \"from\": \"0x627306090abaB3A6e1400e9345bC60c78a8BEf57\", \"to\": \"{{channelAddress}}\", \"value\": \"0x16345785d8a0000\", \"data\": \"0x0\" }], \"id\":1 } To add this to Carol's offchain balance, you need to wait for the tx to be mined and then call: POST {{carolUrl}}/deposit Content-Type: application/json { \"channelAddress\": \"{{carolDaveChannel}}\", \"assetId\": \"0x0000000000000000000000000000000000000000\", \"publicIdentifier\": \"{{carolPublicIdentifier}}\", } Making a Transfer \u00b6 Then, create a transfer between Carol and Dave through Roger (in 3_transfer ): POST {{carolUrl}}/transfers/create Content-Type: application/json { \"type\": \"HashlockTransfer\", \"publicIdentifier\": \"{{carolPublicIdentifier}}\", \"channelAddress\": \"{{carolRogerChannel}}\", \"amount\": \"{{ethAmount}}\", \"assetId\": \"0x0000000000000000000000000000000000000000\", \"details\": { \"lockHash\": \"{{lockHash}}\", \"expiry\": \"0\" }, \"recipient\": \"{{bobPublicIdentifier}}\", \"meta\": { \"routingId\": \"{{routingId}}\", \"hello\": \"world\" } } Lastly, unlock the transfer for Bob to get his funds: POST {{daveUrl}}/transfers/resolve Content-Type: application/json { \"publicIdentifier\": \"{{davePublicIdentifier}}\", \"channelAddress\": \"{{daveRogerChannel}}\", \"routingId\": \"{{routingId}}\", \"preImage\": \"{{preImage}}\" }","title":"Server Node Quick Start"},{"location":"quickStart/serverNode/#server-node-quick-start","text":"This quick start will guide you through getting to a simple e2e transfer flow between two peers running server-nodes (Carol, Dave) that is routed through one intermediary routing node (Roger).","title":"Server Node Quick Start"},{"location":"quickStart/serverNode/#spinning-up-the-stack-locally","text":"Prerequisites: make : Probably already installed, otherwise install w brew install make or apt install make or similar. jq : Probably not installed yet, install w brew install jq or apt install jq or similar. docker : sadly, Docker is kinda annoying to install. See website for instructions. First, clone the repo: git clone git@github.com:connext/vector.git cd vector Then, run: make start-trio The above command will spin up three server-nodes, one with an attached router in dev-mode. Note that in dev-mode, chain and db data will not be persisted between restarts. To run in prod mode, you can spin up a routing node with make start-router and non-routing server-nodes with make start-node . We have a guide on prod-mode deployments and configuration coming soon!","title":"Spinning Up the Stack Locally"},{"location":"quickStart/serverNode/#creating-a-channel","text":"Once you have the above trio set up, you can interact with your nodes via a REST interface. We've documented example requests in the server-node module. If you're developing with VSCode, there are several REST client plugins available in the marketplace that you can use to make these queries directly from the examples . First, set up your nodes (in 0_config ) on the servers to register signers and create the engines. ### Node -> Carol POST {{carolUrl}}/node Content-Type: application/json { \"index\": 0 } ### Node -> Dave POST {{daveUrl}}/node Content-Type: application/json { \"index\": 0 } Then, set up your channels from Carol -> Roger and Roger -> Carol (in 1_Setup ). Note aliceUrl is the internal URL that Carol has access to on the Docker network. In these examples, Carol and Dave are requesting Roger to set up the channel with them so that they can be the \"Bob\" within the channel, which lets them deposit by transferrring directly into the channel address.: ### Carol -> Node POST {{carolUrl}}/setup Content-Type: application/json { \"counterpartyIdentifier\": \"{{rogerPublicIdentifier}}\", \"publicIdentifier\": \"{{carolPublicIdentifier}}\", \"chainId\": \"{{chainId}}\", \"timeout\": \"36000\" } ### Dave -> Node POST {{daveUrl}}/setup Content-Type: application/json { \"counterpartyIdentifier\": \"{{rogerPublicIdentifier}}\", \"publicIdentifier\": \"{{davePublicIdentifier}}\", \"chainId\": \"{{chainId}}\", \"timeout\": \"36000\" }","title":"Creating a Channel"},{"location":"quickStart/serverNode/#depositing-into-a-channel","text":"Then, send an Eth deposit to Carol's channel onchain. This can be done by connecting Metamask to your local EVM at http://localhost:8545 and sending a transfer directly to the channelAddress , at any time, regardless of either channel participant's liveness status. A convenient way to do this using HTTP JSON-RPC calls is with a POST request: # Send a transaction to {{channelAddress}} for 100000000000000000 Wei POST http://localhost:8545 Content-Type: application/json { \"jsonrpc\":\"2.0\", \"method\":\"eth_sendTransaction\", \"params\":[{ \"from\": \"0x627306090abaB3A6e1400e9345bC60c78a8BEf57\", \"to\": \"{{channelAddress}}\", \"value\": \"0x16345785d8a0000\", \"data\": \"0x0\" }], \"id\":1 } To add this to Carol's offchain balance, you need to wait for the tx to be mined and then call: POST {{carolUrl}}/deposit Content-Type: application/json { \"channelAddress\": \"{{carolDaveChannel}}\", \"assetId\": \"0x0000000000000000000000000000000000000000\", \"publicIdentifier\": \"{{carolPublicIdentifier}}\", }","title":"Depositing Into a Channel"},{"location":"quickStart/serverNode/#making-a-transfer","text":"Then, create a transfer between Carol and Dave through Roger (in 3_transfer ): POST {{carolUrl}}/transfers/create Content-Type: application/json { \"type\": \"HashlockTransfer\", \"publicIdentifier\": \"{{carolPublicIdentifier}}\", \"channelAddress\": \"{{carolRogerChannel}}\", \"amount\": \"{{ethAmount}}\", \"assetId\": \"0x0000000000000000000000000000000000000000\", \"details\": { \"lockHash\": \"{{lockHash}}\", \"expiry\": \"0\" }, \"recipient\": \"{{bobPublicIdentifier}}\", \"meta\": { \"routingId\": \"{{routingId}}\", \"hello\": \"world\" } } Lastly, unlock the transfer for Bob to get his funds: POST {{daveUrl}}/transfers/resolve Content-Type: application/json { \"publicIdentifier\": \"{{davePublicIdentifier}}\", \"channelAddress\": \"{{daveRogerChannel}}\", \"routingId\": \"{{routingId}}\", \"preImage\": \"{{preImage}}\" }","title":"Making a Transfer"},{"location":"reference/nodeAPI/","text":"Node API Reference \u00b6 There is one consolidated API across both the server-node and browser-node . Server nodes expose that interface via HTTP and gRPC (coming soon), and we additionally have an example TS \"client\" which wraps the HTTP methods. The browser node exposes a TS interface only. Base Objects \u00b6 Balance \u00b6 Balance : object - contains: to : string[] - Signing keys of channel participants ordered by channel [initiator, responder] . amount : string[] - Amount of balance for the given assetId, ordered by channel [initiator, responder] . Full Channel State \u00b6 FullChannelState : object - contains: assetIds : string[] - Array of assetIds for assets that are managed by this channel. balances : object[] - Array of Balance objects indexed by the above assetIds array. channelAddress : string - Unique onchain address of the channel. alice : string - Signing key of channel initiator, i.e. the party that first called setup . bob : string - Signing key of channel responder, i.e. the party who responded to setup . merkleRoot : string - Root hash containing merkelized data from active transfers and balances. Used by the onchain contracts as part of disputing. nonce : number - Monotonically increasing number which is incremented for every update to the channel. Used by the onchain contracts as part of disputing. processedDepositsA : string[] - Offchain tracker of total amount of deposits reconciled into the channel balance for the channel initiator, indexed by assetIds array above. used by onchain contracts as part of disputing. processedDepositsB : string[] - Offchain tracker of total amount of deposits reconciled into the channel balance for the channel responder, indexed by assetIds array above. used by onchain contracts as part of disputing. timeout : string - Timeout within which onchain disputes are settled designated as number of blocks. aliceIdentifier : string - Public identifier of the channel initiator. bobIdentifier : string - Public identifier of the channel responder. latestUpdate : object - Latest update that was mutually agreed on in the channel by both parties. networkContext : object - Chain specific data used for disputing. Includes: channelFactoryAddress : string - Address of ChannelFactory.sol contract for the chain that this channel is on. channelMastercopyAddress : string - Address of ChannelMastercopy.sol contract for the chain that this channel is on. transferRegistryAddress : string - Address of TransferRegistry.sol contract for the chain that this channel is on. chainId : number - Chainid of the chain that this channel is on. providerUrl : string - Chain provider that this node instance was initiated with (associated with this chainId). Full Transfer State \u00b6 FullTransferState : object - contains: balance : object - Balance object. assetId : string - Id of the asset that is being sent as part of this transfer. channelAddress : string - Unique onchain address of the channel. transferId : string - Unique identifier associated with this transfer. transferDefinition : string - Onchain address of the contract logic that will be used to govern this transfer. transferTimeout : string - Transfer-specific dispute timeout within which the transfer state must be settled onchain. initialStateHash : string - Hash of the initial state of the transfer as defined in the transferDefinition contract. initiator : string - Signing key of the initiator of the transfer (the peer that calls conditionalTransfer ). responder : string - Signing key of the responder of the transfer (the peer that calls resolveTransfer ). channelFactoryAddress : string - Address of the ChannelFactory.sol contract. chainId : number - Unique id of the chain that this channel is on. transferEncodings : string[] - [ABIEncoderV2] encodings for [transferState, transferResolver] . transferState : Initial state of the transfer as defined in the transferDefinition contract. transferResolver : Data needed to resolve the transfer as defined in the transferDefinition contract. meta : object - User-defined object for optional metadata sent along with the transfer (e.g. Invoice number, messages, etc.) Core Methods \u00b6 createNode \u00b6 Warning createNode is a server-node only method. It is not relevant to the browser-node . See the indexed engines documentation for details. Creates a new node engine (i.e. a new signer + publicIdentifier ) at the given index. Example TS const result = await node . createNode ({ index : 0 }); HTTP ############## ### CREATE NODE POST {{nodeUrl}}/node Content-Type: application/json { \"index\": 0 } Params ServerNodeParams.CreateNode object. Contains: index : number - used as part of the path along which a new key will be derived. This key is then used to create a new signer/public identifier/node engine. Returns EITHER ServerNodeResponses.CreateNode object. Contains: publicIdentifier : Unique Connext-specific identifier for the node. signerAddress : Address of the key that is used to to sign messages in the channel. This is linked 1:1 with the publicIdentifier . index : Derivation index, same as what was passed in as a param. OR NodeError setup \u00b6 Creates a channel with a given counterparty. Example TS const result = await node . setup ({ chainId : 1 // Ethereum counterpartyPublicIdentifier : \"indra123ABC...\" }); HTTP ############## ### Setup Channel POST {{nodeUrl}}/setup Content-Type: application/json { \"counterpartyPublicIdentifier\": \"indra123ABC...\", \"chainId\": 1, } Params ServerNodeParams.Setup object. Contains: chainId : number - chainId of the chain on which the channel will be created. counterpartyIdentifier : string - Identifier of the peer that you want to open a channel to. // TODO: make timeout optional timeout : string - (Optional) Onchain dispute timeout of the channel in blocks. Returns EITHER ServerNodeResponses.Setup object. Contains: channelAddress : Unique onchain address of the new channel. OR NodeError reconcileDeposit \u00b6 Reconciles an onchain deposit with your offchain balance. It is assumed when calling this function that a deposit tx to your channelAddress has already occurred and been mined. Example TS const result = await node . reconcileDeposit ({ channelAddress : \"0xABC123...\" , assetId : \"0x0000000000000000000000000000000000000000\" // \"0x0\" == Base asset of whatever chain the channel is on, e.g $ETH }); HTTP ############## ### Reconcile Deposit POST {{nodeUrl}}/deposit Content-Type: application/json { \"channelAddress\": \"0xABC123...\", \"assetId\": \"0x0000000000000000000000000000000000000000\" } Params ServerNodeParams.Deposit object. Contains: channelAddress : string - Unique onchain address of your channel. This should be the same address that the onchain funding tx was sent to. assetId : string - Address of the asset on whatever chain your channel is on. For instance, the ERC20 contract address for a token on Ethereum. We use 0x0000000000000000000000000000000000000000 to represent the base asset of the chain, e.g. $ETH on chainId == 1 Returns EITHER ServerNodeResponses.Deposit object. Contains: channelAddress : string - Unique onchain address of your channel. OR NodeError conditionalTransfer \u00b6 Creates a conditional transfer to a given counterparty, locking up the transfer balance and setting some logic by which the transfer will be unlocked. See Transfers for more information. Example TS const result = await node . conditionalTransfer ({ type : \"HashlockTransfer\" , channelAddress : \"0xABC123...\" , amount : \"1000000000000000\" , // 0.01 ETH assetId : \"0x0000000000000000000000000000000000000000\" , details : { lockHash : \"0xlockHash...\" , expiry : \"0\" }, recipient : \"indra123ABC...\" , meta : { hello : \"world\" } }); HTTP ############## ### Create Transfer ETH POST {{nodeUrl}}/transfers/create Content-Type: application/json { \"type\": \"HashlockTransfer\", \"channelAddress\": \"0xABC123...\", \"amount\": \"1000000000000000\", # 0.01 ETH \"assetId\": \"0x0000000000000000000000000000000000000000\", \"details\": { \"lockHash\": \"0xlockHash...\", \"expiry\": \"0\" }, \"recipient\": \"indra123ABC...\", \"meta\": { \"hello\": \"world\" } } Params ServerNodeParams.ConditionalTransfer object. Contains: channelAddress : string - Unique onchain address of the channel in which the transfer will be executed. amount : string - Amount to be transferred represented in decimal-free units. For instance, with $ETH we should use wei units . assetId : string - Address of the asset on whatever chain your channel is on. For instance, the ERC20 contract address for a token on Ethereum. We use 0x0000000000000000000000000000000000000000 to represent the base asset of the chain, e.g. $ETH on chainId == 1 recipient : string - Identifier of the peer that you want to transfer to. // TODO where do we have a list of transfernames? type : string - Either of a hardcoded TransferName if the transfer type is officially supported by Connext, OR a transferDefinition , which is the onchain address of the logic which will be used to govern the transfer. details : object - initial state of the transfer, used to set up the conditions which are used to unlock the transfer. This should be exactly the same as the TransferState defined in your transferDefinition contract. recipientChainId : number - (Optional) chainId of chain on which the recipient is located. The recipient's channel does not need to be on the same chain as the sender's channel - for example, you could send a transfer from Alice on Ethereum to Bob on Matic. If recipientChainId is not provided, it will default to the chainId of the sender's channel. recipientAssetId : string - (Optional) Similar to recipientChainId , the assetId that the recipient receives a transfer in does not need to be the same as the asset that the transfer is sent in. If intermediary routers are willing to provide liquidity, Alice can send a transfer in $ETH which can be receives by Bob in $DAI. If recipientAssetId is not provided, it will default to the assetId above. meta : object - (Optional) User-defined object for any additional metadata to be sent with the transfer creation e.g. Invoice numbers, messages, etc. Returns EITHER ServerNodeResponses.ConditionalTransfer object. Contains: channelAddress : string - Unique onchain address of your channel. transferId : string - Unique identifier for a given transfer. OR NodeError resolveTransfer \u00b6 Unlocks a transfer from a counterparty by passing in whatever params are needed to resolve the condition defined in a corresponding conditionalTransfer . Note that if Alice creates a conditional transfer to Bob, only Bob can resolveTransfer on it. Example TS const result = await node . resolveTransfer ({ channelAddress : \"0xABC123...\" , transferId : \"0xtransferId...\" , transferResolver : { preImage : \"0xpreimage...\" // For hashlock transfer } }); HTTP ############## ### Resolve Transfer POST {{nodeUrl}}/transfers/resolve Content-Type: application/json { \"channelAddress\": \"0xABC123...\", \"transferId\": \"0xtransferId...\", \"transferResolver\": { \"preImage\": \"0xpreimage...\" # For hashlock transfer } } Params ServerNodeParams.ResolveTransfer object. Contains: channelAddress : string - Unique onchain address of the channel in which a conditional transfer has been received. transferId : string - Unique identifier of the received conditional transfer. transferResolver : object - params needed to resolve the conditional transfer. This should be exactly the same as the TransferResolver defined in your transferDefinition contract. meta : object - (Optional) User-defined object for any additional metadata to be sent with the transfer resolution e.g. Invoice numbers, messages, etc. Returns EITHER ServerNodeResponses.ResolveTransfer object. Contains: channelAddress : string - Unique onchain address of your channel. transferId : string - Unique identifier for a given transfer. OR NodeError withdraw \u00b6 A special kind of conditional transfer that sends assets in your channel to a specified onchain address. Can optionally include a fee as part of the withdraw which is charged by the counterparty if they submit the transaction on behalf of the withdrawer (i.e. if the counterparty is performing a metatransaction to remove the withdrawer's need to pay gas) Example TS const result = await node . withdraw ({ channelAddress : \"0xABC123...\" , amount : \"1000000000000000\" , // 0.01 ETH, assetId : \"0x0000000000000000000000000000000000000000\" , recipient : \"0xmyAddress...\" , fee : \"10000000000\" // 10 gWei }); HTTP ############## ### Alice Withdraw POST {{nodeUrl}}/withdraw Content-Type: application/json { \"channelAddress\": \"0xABC123...\", \"amount\": \"1000000000000000\", # 0.01 ETH \"assetId\": \"0x0000000000000000000000000000000000000000\", \"recipient\": \"0xmyAddress...\", \"fee\": \"10000000000\" # 10 gWei } Params ServerNodeParams.Withdraw object. Contains: channelAddress : string - Unique onchain address of the channel in which a conditional transfer has been received. amount : string - Amount to be withdrawn from channel in decimal-free units. For instance, for $ETH, we would use wei . assetId : string - Address of the asset on whatever chain your channel is on. For instance, the ERC20 contract address for a token on Ethereum. We use 0x0000000000000000000000000000000000000000 to represent the base asset of the chain, e.g. $ETH on chainId == 1 recipient : string - Onchain address to which the withdraw will be made. fee : string - (Optional) Fee that will be charged by the counterparty for the withdraw. It's up to the counterparty to implement validation logic to verify that the correct fee is being supplied by the caller. Fee is also in decimal-free units, just like amount . Returns EITHER ServerNodeResponses.Withdraw object. Contains: channelAddress : string - Unique onchain address of your channel. transferId : string - Unique identifier for the withdraw. OR NodeError Getters and Static Properties \u00b6 publicIdentifier \u00b6 Unique identifier associated with your identity - 1:1 mapped with your signing key. Example TS const result = node . publicIdentifier ; HTTP ## TODO Params None Returns publicIdentifier : string signerAddress \u00b6 Public address of your signing key - 1:1 mapped with your public identifier. Example TS const result = node . signerAddress ; HTTP ## TODO Params None Returns signerAddress : string getStateChannelByParticipants \u00b6 Gets a channel given the participant public identifiers of that channel. Example TS const result = await node . getStateChannelByParticipants ({ publicIdentifier : \"indra123MyId...\" , counterparty : \"indra456TheirId...\" , chainId : 1 // Ethereum }); HTTP ############## ### getChannelByParticipants GET {{nodeUrl}}/indra123MyId.../channels/counterparty/indra456TheirId.../chain-id/1 Params ServerNodeParams.GetChannelStateByParticipants object. Contains: publicIdentifier : string - Your unique Connext-specific identifier. counterparty : string - Counterparty's unique Connext-specific identifier. chainId : number - - chainId of the chain on which the channel was created. Returns ServerNodeResponses.GetChannelStateByParticipants object. Contains: FullChannelState : object - Channel state . getStateChannels \u00b6 Gets all state channels in your store associated with your signer/public identifier. Example TS const result = await node . getStateChannels (); HTTP ############## ### GET CHANNELS GET {{nodeUrl}}/channel Params None Returns ServerNodeResponses.GetChannelStates object. Contains: string[] : Array of all channelAddresses found in store getStateChannel \u00b6 Gets a channel given its channelAddress . Example TS const result = await node . getStateChannel ({ channelAddress : \"0xABC123...\" }); HTTP ############## ### GET CHANNEL GET {{nodeUrl}}/channel/0xABC123... Params ServerNodeParams.GetChannelState object. Contains: channelAddress : string - Unique onchain address of your channel Returns EITHER ServerNodeResponses.GetChannelState object. Contains: string[] : Array of all channelAddresses found in store OR NodeError getTransfer \u00b6 Gets a transfer given its transferId . Example TS const result = await node . getTransfer ({ transferId : \"0xtransferId...\" }); HTTP ############## ### GET TRANSFER GET {{nodeUrl}}/transfer/0xtransferId... Params ServerNodeParams.GetTransferState object. Contains: transferId : string - Unique id of transfer Returns EITHER ServerNodeResponses.GetTransferState object. Contains: FullTransferState : object - Transfer state . OR NodeError getActiveTransfers \u00b6 Gets all active transfers for a given channel address. Example TS const result = await node . getActiveTransfers ({ channelAddress : \"0xABC123...\" }); HTTP ## TODO Params ServerNodeParams.GetActiveTransfersByChannelAddress object. Contains: channelAddress : string - Unique onchain address of your channel. Returns EITHER ServerNodeResponses.GetActiveTransfersByChannelAddress object. Contains: FullTransferState[] : object[] - Array of transfer states . OR NodeError Event Handler Methods \u00b6 Event Types and Payloads \u00b6 Setup \u00b6 \"SETUP\" - Emitted on channel setup. Payload SetupPayload object. Contains: channelAddress : string - Unique onchain address of your channel. aliceIdentifier : string - Connext-specific identifier associated with the initiator of the channel (i.e. the peer that called setup ). bobIdentifier : string - Connext-specific identifier associated with the responded of the channel (i.e. the peer that responded to setup ). chainId : number - Chainid that the channel has been set up on. Conditiona Transfer Created \u00b6 \"CONDITIONAL_TRANSFER_CREATED\" - Emitted on creation of a conditional transfer. Payload ConditionalTransferCreatedPayload object. Contains: aliceIdentifier : string - Connext-specific identifier associated with the initiator of the channel (i.e. the peer that called setup ). bobIdentifier : string - Connext-specific identifier associated with the responded of the channel (i.e. the peer that responded to setup ). channelAddress : string - Unique onchain address of your channel. transfer : FullTransferState - Full transfer state . channelBalance : Balance - Balance . conditionType : string - Either of a hardcoded TransferName for a transfer supported by default in connext OR a transferDefinition address for a custom transfer. Conditional Transfer Resolved \u00b6 \"CONDITIONAL_TRANSFER_RESOLVED\" - Emitted on resolve of a conditional transfer. Payload ConditionalTransferResolvedPayload object. Contains: aliceIdentifier : string - Connext-specific identifier associated with the initiator of the channel (i.e. the peer that called setup ). bobIdentifier : string - Connext-specific identifier associated with the responded of the channel (i.e. the peer that responded to setup ). channelAddress : string - Unique onchain address of your channel. transfer : FullTransferState - Full transfer state . channelBalance : Balance - Balance . conditionType : string - Either of a hardcoded TransferName for a transfer supported by default in connext OR a transferDefinition address for a custom transfer. Deposit Reconciled \u00b6 \"DEPOSIT_RECONCILED\" - Emitted after a channel party reconciles a deposit. Payload DepositReconciledPayload object. Contains: aliceIdentifier : string - Connext-specific identifier associated with the initiator of the channel (i.e. the peer that called setup ). bobIdentifier : string - Connext-specific identifier associated with the responded of the channel (i.e. the peer that responded to setup ). channelAddress : string - Unique onchain address of your channel. channelBalance : Balance - Balance . assetId : string - Address of the asset onchain. E.g. ERC20 token address. We use 0x0 for the base asset of the chain ($ETH on Ethereum). Withdrawal Created \u00b6 \"WITHDRAWAL_CREATED\" - Emitted after a withdraw is initiated with a counterparty. Payload WithdrawalCreatedPayload object. Contains: aliceIdentifier : string - Connext-specific identifier associated with the initiator of the channel (i.e. the peer that called setup ). bobIdentifier : string - Connext-specific identifier associated with the responded of the channel (i.e. the peer that responded to setup ). channelAddress : string - Unique onchain address of your channel. transfer : FullTransferState - Full Transfer State fee : string - Fee submitted by withdraw initiator. assetId : string - Address of the asset onchain. E.g. ERC20 token address. We use 0x0 for the base asset of the chain ($ETH on Ethereum). amount : string - Amount to be withdrawn in decimal-free units. E.g. wei for $ETH recipient : string - Onchain address that the withdrawn amount will be sent to. channelBalance : Balance - Updated balance for the above assetId. Withdrawal Resolved \u00b6 \"WITHDRAWAL_RESOLVED\" - Emitted after a withdraw has been completed and a signed commitment to sent funds onchain has been successfully generated. Payload WithdrawalResolvedPayload object. Contains: aliceIdentifier : string - Connext-specific identifier associated with the initiator of the channel (i.e. the peer that called setup ). bobIdentifier : string - Connext-specific identifier associated with the responded of the channel (i.e. the peer that responded to setup ). channelAddress : string - Unique onchain address of your channel. transfer : FullTransferState - Full Transfer State fee : string - Fee submitted by withdraw initiator. assetId : string - Address of the asset onchain. E.g. ERC20 token address. We use 0x0 for the base asset of the chain ($ETH on Ethereum). amount : string - Amount to be withdrawn in decimal-free units. E.g. wei for $ETH recipient : string - Onchain address that the withdrawn amount will be sent to. channelBalance : Balance - Updated balance for the above assetId. Withdrawal Reconciled \u00b6 \"WITHDRAWAL_RECONCILED\" - Emitted after a withdraw commitment has been successfully sent to chain. Payload WithdrawalReconciledPayload object. Contains: aliceIdentifier : string - Connext-specific identifier associated with the initiator of the channel (i.e. the peer that called setup ). bobIdentifier : string - Connext-specific identifier associated with the responded of the channel (i.e. the peer that responded to setup ). channelAddress : string - Unique onchain address of your channel. transactionHash : string - Onchain transaction hash of submitted withdraw tx. transferId : string - Unique id associated with this withdraw.","title":"Node API Reference"},{"location":"reference/nodeAPI/#node-api-reference","text":"There is one consolidated API across both the server-node and browser-node . Server nodes expose that interface via HTTP and gRPC (coming soon), and we additionally have an example TS \"client\" which wraps the HTTP methods. The browser node exposes a TS interface only.","title":"Node API Reference"},{"location":"reference/nodeAPI/#base-objects","text":"","title":"Base Objects"},{"location":"reference/nodeAPI/#balance","text":"Balance : object - contains: to : string[] - Signing keys of channel participants ordered by channel [initiator, responder] . amount : string[] - Amount of balance for the given assetId, ordered by channel [initiator, responder] .","title":"Balance"},{"location":"reference/nodeAPI/#full-channel-state","text":"FullChannelState : object - contains: assetIds : string[] - Array of assetIds for assets that are managed by this channel. balances : object[] - Array of Balance objects indexed by the above assetIds array. channelAddress : string - Unique onchain address of the channel. alice : string - Signing key of channel initiator, i.e. the party that first called setup . bob : string - Signing key of channel responder, i.e. the party who responded to setup . merkleRoot : string - Root hash containing merkelized data from active transfers and balances. Used by the onchain contracts as part of disputing. nonce : number - Monotonically increasing number which is incremented for every update to the channel. Used by the onchain contracts as part of disputing. processedDepositsA : string[] - Offchain tracker of total amount of deposits reconciled into the channel balance for the channel initiator, indexed by assetIds array above. used by onchain contracts as part of disputing. processedDepositsB : string[] - Offchain tracker of total amount of deposits reconciled into the channel balance for the channel responder, indexed by assetIds array above. used by onchain contracts as part of disputing. timeout : string - Timeout within which onchain disputes are settled designated as number of blocks. aliceIdentifier : string - Public identifier of the channel initiator. bobIdentifier : string - Public identifier of the channel responder. latestUpdate : object - Latest update that was mutually agreed on in the channel by both parties. networkContext : object - Chain specific data used for disputing. Includes: channelFactoryAddress : string - Address of ChannelFactory.sol contract for the chain that this channel is on. channelMastercopyAddress : string - Address of ChannelMastercopy.sol contract for the chain that this channel is on. transferRegistryAddress : string - Address of TransferRegistry.sol contract for the chain that this channel is on. chainId : number - Chainid of the chain that this channel is on. providerUrl : string - Chain provider that this node instance was initiated with (associated with this chainId).","title":"Full Channel State"},{"location":"reference/nodeAPI/#full-transfer-state","text":"FullTransferState : object - contains: balance : object - Balance object. assetId : string - Id of the asset that is being sent as part of this transfer. channelAddress : string - Unique onchain address of the channel. transferId : string - Unique identifier associated with this transfer. transferDefinition : string - Onchain address of the contract logic that will be used to govern this transfer. transferTimeout : string - Transfer-specific dispute timeout within which the transfer state must be settled onchain. initialStateHash : string - Hash of the initial state of the transfer as defined in the transferDefinition contract. initiator : string - Signing key of the initiator of the transfer (the peer that calls conditionalTransfer ). responder : string - Signing key of the responder of the transfer (the peer that calls resolveTransfer ). channelFactoryAddress : string - Address of the ChannelFactory.sol contract. chainId : number - Unique id of the chain that this channel is on. transferEncodings : string[] - [ABIEncoderV2] encodings for [transferState, transferResolver] . transferState : Initial state of the transfer as defined in the transferDefinition contract. transferResolver : Data needed to resolve the transfer as defined in the transferDefinition contract. meta : object - User-defined object for optional metadata sent along with the transfer (e.g. Invoice number, messages, etc.)","title":"Full Transfer State"},{"location":"reference/nodeAPI/#core-methods","text":"","title":"Core Methods"},{"location":"reference/nodeAPI/#createnode","text":"Warning createNode is a server-node only method. It is not relevant to the browser-node . See the indexed engines documentation for details. Creates a new node engine (i.e. a new signer + publicIdentifier ) at the given index. Example TS const result = await node . createNode ({ index : 0 }); HTTP ############## ### CREATE NODE POST {{nodeUrl}}/node Content-Type: application/json { \"index\": 0 }","title":"createNode"},{"location":"reference/nodeAPI/#setup","text":"Creates a channel with a given counterparty. Example TS const result = await node . setup ({ chainId : 1 // Ethereum counterpartyPublicIdentifier : \"indra123ABC...\" }); HTTP ############## ### Setup Channel POST {{nodeUrl}}/setup Content-Type: application/json { \"counterpartyPublicIdentifier\": \"indra123ABC...\", \"chainId\": 1, }","title":"setup"},{"location":"reference/nodeAPI/#reconciledeposit","text":"Reconciles an onchain deposit with your offchain balance. It is assumed when calling this function that a deposit tx to your channelAddress has already occurred and been mined. Example TS const result = await node . reconcileDeposit ({ channelAddress : \"0xABC123...\" , assetId : \"0x0000000000000000000000000000000000000000\" // \"0x0\" == Base asset of whatever chain the channel is on, e.g $ETH }); HTTP ############## ### Reconcile Deposit POST {{nodeUrl}}/deposit Content-Type: application/json { \"channelAddress\": \"0xABC123...\", \"assetId\": \"0x0000000000000000000000000000000000000000\" }","title":"reconcileDeposit"},{"location":"reference/nodeAPI/#conditionaltransfer","text":"Creates a conditional transfer to a given counterparty, locking up the transfer balance and setting some logic by which the transfer will be unlocked. See Transfers for more information. Example TS const result = await node . conditionalTransfer ({ type : \"HashlockTransfer\" , channelAddress : \"0xABC123...\" , amount : \"1000000000000000\" , // 0.01 ETH assetId : \"0x0000000000000000000000000000000000000000\" , details : { lockHash : \"0xlockHash...\" , expiry : \"0\" }, recipient : \"indra123ABC...\" , meta : { hello : \"world\" } }); HTTP ############## ### Create Transfer ETH POST {{nodeUrl}}/transfers/create Content-Type: application/json { \"type\": \"HashlockTransfer\", \"channelAddress\": \"0xABC123...\", \"amount\": \"1000000000000000\", # 0.01 ETH \"assetId\": \"0x0000000000000000000000000000000000000000\", \"details\": { \"lockHash\": \"0xlockHash...\", \"expiry\": \"0\" }, \"recipient\": \"indra123ABC...\", \"meta\": { \"hello\": \"world\" } }","title":"conditionalTransfer"},{"location":"reference/nodeAPI/#resolvetransfer","text":"Unlocks a transfer from a counterparty by passing in whatever params are needed to resolve the condition defined in a corresponding conditionalTransfer . Note that if Alice creates a conditional transfer to Bob, only Bob can resolveTransfer on it. Example TS const result = await node . resolveTransfer ({ channelAddress : \"0xABC123...\" , transferId : \"0xtransferId...\" , transferResolver : { preImage : \"0xpreimage...\" // For hashlock transfer } }); HTTP ############## ### Resolve Transfer POST {{nodeUrl}}/transfers/resolve Content-Type: application/json { \"channelAddress\": \"0xABC123...\", \"transferId\": \"0xtransferId...\", \"transferResolver\": { \"preImage\": \"0xpreimage...\" # For hashlock transfer } }","title":"resolveTransfer"},{"location":"reference/nodeAPI/#withdraw","text":"A special kind of conditional transfer that sends assets in your channel to a specified onchain address. Can optionally include a fee as part of the withdraw which is charged by the counterparty if they submit the transaction on behalf of the withdrawer (i.e. if the counterparty is performing a metatransaction to remove the withdrawer's need to pay gas) Example TS const result = await node . withdraw ({ channelAddress : \"0xABC123...\" , amount : \"1000000000000000\" , // 0.01 ETH, assetId : \"0x0000000000000000000000000000000000000000\" , recipient : \"0xmyAddress...\" , fee : \"10000000000\" // 10 gWei }); HTTP ############## ### Alice Withdraw POST {{nodeUrl}}/withdraw Content-Type: application/json { \"channelAddress\": \"0xABC123...\", \"amount\": \"1000000000000000\", # 0.01 ETH \"assetId\": \"0x0000000000000000000000000000000000000000\", \"recipient\": \"0xmyAddress...\", \"fee\": \"10000000000\" # 10 gWei }","title":"withdraw"},{"location":"reference/nodeAPI/#getters-and-static-properties","text":"","title":"Getters and Static Properties"},{"location":"reference/nodeAPI/#publicidentifier","text":"Unique identifier associated with your identity - 1:1 mapped with your signing key. Example TS const result = node . publicIdentifier ; HTTP ## TODO","title":"publicIdentifier"},{"location":"reference/nodeAPI/#signeraddress","text":"Public address of your signing key - 1:1 mapped with your public identifier. Example TS const result = node . signerAddress ; HTTP ## TODO","title":"signerAddress"},{"location":"reference/nodeAPI/#getstatechannelbyparticipants","text":"Gets a channel given the participant public identifiers of that channel. Example TS const result = await node . getStateChannelByParticipants ({ publicIdentifier : \"indra123MyId...\" , counterparty : \"indra456TheirId...\" , chainId : 1 // Ethereum }); HTTP ############## ### getChannelByParticipants GET {{nodeUrl}}/indra123MyId.../channels/counterparty/indra456TheirId.../chain-id/1","title":"getStateChannelByParticipants"},{"location":"reference/nodeAPI/#getstatechannels","text":"Gets all state channels in your store associated with your signer/public identifier. Example TS const result = await node . getStateChannels (); HTTP ############## ### GET CHANNELS GET {{nodeUrl}}/channel","title":"getStateChannels"},{"location":"reference/nodeAPI/#getstatechannel","text":"Gets a channel given its channelAddress . Example TS const result = await node . getStateChannel ({ channelAddress : \"0xABC123...\" }); HTTP ############## ### GET CHANNEL GET {{nodeUrl}}/channel/0xABC123...","title":"getStateChannel"},{"location":"reference/nodeAPI/#gettransfer","text":"Gets a transfer given its transferId . Example TS const result = await node . getTransfer ({ transferId : \"0xtransferId...\" }); HTTP ############## ### GET TRANSFER GET {{nodeUrl}}/transfer/0xtransferId...","title":"getTransfer"},{"location":"reference/nodeAPI/#getactivetransfers","text":"Gets all active transfers for a given channel address. Example TS const result = await node . getActiveTransfers ({ channelAddress : \"0xABC123...\" }); HTTP ## TODO","title":"getActiveTransfers"},{"location":"reference/nodeAPI/#event-handler-methods","text":"","title":"Event Handler Methods"},{"location":"reference/nodeAPI/#event-types-and-payloads","text":"","title":"Event Types and Payloads"},{"location":"reference/nodeAPI/#setup_1","text":"\"SETUP\" - Emitted on channel setup.","title":"Setup"},{"location":"reference/nodeAPI/#conditiona-transfer-created","text":"\"CONDITIONAL_TRANSFER_CREATED\" - Emitted on creation of a conditional transfer.","title":"Conditiona Transfer Created"},{"location":"reference/nodeAPI/#conditional-transfer-resolved","text":"\"CONDITIONAL_TRANSFER_RESOLVED\" - Emitted on resolve of a conditional transfer.","title":"Conditional Transfer Resolved"},{"location":"reference/nodeAPI/#deposit-reconciled","text":"\"DEPOSIT_RECONCILED\" - Emitted after a channel party reconciles a deposit.","title":"Deposit Reconciled"},{"location":"reference/nodeAPI/#withdrawal-created","text":"\"WITHDRAWAL_CREATED\" - Emitted after a withdraw is initiated with a counterparty.","title":"Withdrawal Created"},{"location":"reference/nodeAPI/#withdrawal-resolved","text":"\"WITHDRAWAL_RESOLVED\" - Emitted after a withdraw has been completed and a signed commitment to sent funds onchain has been successfully generated.","title":"Withdrawal Resolved"},{"location":"reference/nodeAPI/#withdrawal-reconciled","text":"\"WITHDRAWAL_RECONCILED\" - Emitted after a withdraw commitment has been successfully sent to chain.","title":"Withdrawal Reconciled"},{"location":"router/basics/","text":"Basics \u00b6 Router is an automated module that allows a server-node to act as an intermediary in hopped transactions between different peers in a network. For now, nodes that have the router enabled, i.e. routing nodes can only forward transfers to non-routing peers. Eventually, this routing module can be expanded to allow routing nodes to route value to other routing nodes, thereby creating a fully-decentralized state channel network. Responsibilities \u00b6 Router consumes the server-node gRPC interface to do the following: Listen to incoming events from the node for inbound transfers. Parse the transfer metadata to find routing information (recipient, chainId, assetId, requireOnline, etc.). Look up the recipient's channel using the above info. Check that the recipient's channel has enough collateral. If not, send a deposit to collateralize the channel and wait for it to be completed. As part of resolving transfers, the router will also reclaim collateral from channels. Dispatch the transfer. If the transfer fails and the transfer requires that the recipient is online, then hard error and cancel the sender side transfer too. Else, store the transfer and wait for the recipient to come back online. When a recipient comes online, the node emits an isAlive event for that channel. Router should catch isAlive events and complete all pending transfers to the recipient. Note that validation around allowed transfer types all happens in the node itself.","title":"Basics"},{"location":"router/basics/#basics","text":"Router is an automated module that allows a server-node to act as an intermediary in hopped transactions between different peers in a network. For now, nodes that have the router enabled, i.e. routing nodes can only forward transfers to non-routing peers. Eventually, this routing module can be expanded to allow routing nodes to route value to other routing nodes, thereby creating a fully-decentralized state channel network.","title":"Basics"},{"location":"router/basics/#responsibilities","text":"Router consumes the server-node gRPC interface to do the following: Listen to incoming events from the node for inbound transfers. Parse the transfer metadata to find routing information (recipient, chainId, assetId, requireOnline, etc.). Look up the recipient's channel using the above info. Check that the recipient's channel has enough collateral. If not, send a deposit to collateralize the channel and wait for it to be completed. As part of resolving transfers, the router will also reclaim collateral from channels. Dispatch the transfer. If the transfer fails and the transfer requires that the recipient is online, then hard error and cancel the sender side transfer too. Else, store the transfer and wait for the recipient to come back online. When a recipient comes online, the node emits an isAlive event for that channel. Router should catch isAlive events and complete all pending transfers to the recipient. Note that validation around allowed transfer types all happens in the node itself.","title":"Responsibilities"},{"location":"router/chains/","text":"Adding a Chain \u00b6 Requirements \u00b6 Chain Requirements \u00b6 To integrate with connext your chain must have: evm compatability ABIEncoderV2 support EC_RECOVER support keccak256 support same math quirks as solidity (i.e. must underflow and overflow in the same way if your contract is NOT using safe math) blocktime/timestamp support solidity v7 support If your chain meets some, but not all, of these requirements, reach out to the Connext team for more detailed integration tests. Contract Testing \u00b6 If there is any concern about whether your chain supports the required behavior, it is possible to run the full contract test suite against your chain: Add the network information to the hardhat.config.ts . Specifically, include: a funded mnemonic a chainId a provider url Run the test suite using: $ bash ops/test-network.sh <NETWORK_NAME> <CHAIN_PROVIDERS> <FUNDED_MNEMONIC> # i.e. for running against matic: # bash ops/test-network.sh \"matic\" '{ \"80001\" : \"https://rpc-mumbai.matic.today\" }' \"candy maple cake sugar pudding cream honey rich smooth crumble sweet treat\" NOTE These tests are expensive to run, and should be done against a testnet. Integration Testing \u00b6 To test a local trio setup against a remote chain: Deploy the contracts to your chain bash ops/deploy-contracts.sh -p <PROVIDER_URL> -m <FUNDED_MNEMONIC> -a <ADDRESS_BOOK_PATH> # the cli inputs are all optional, and if not provided will use the following defaults: # m: \"candy maple cake sugar pudding cream honey rich smooth crumble sweet treat\" # p: \"http://localhost:8545\" # a: \"./address-book.json\" Make sure there is a node.config.json and a router.config.json in the root of your vector directory. If one does not exist run: make config to create files with the preconfigured defaults for a local setup. Update the chainProviders and chainAddresses fields in the node.config.json to include the providers and deployed contract addresses for your network, respectively. Make sure to keep the formatting consistent. See the node configuration section for more information. Update the rebalanceProfiles field in router.config.json to include an entry for the chain with appropriate collateralization values for the native asset. See the router configuration section for more information. Run the trio happy case tests with: make test-trio","title":"Adding a Chain"},{"location":"router/chains/#adding-a-chain","text":"","title":"Adding a Chain"},{"location":"router/chains/#requirements","text":"","title":"Requirements"},{"location":"router/chains/#chain-requirements","text":"To integrate with connext your chain must have: evm compatability ABIEncoderV2 support EC_RECOVER support keccak256 support same math quirks as solidity (i.e. must underflow and overflow in the same way if your contract is NOT using safe math) blocktime/timestamp support solidity v7 support If your chain meets some, but not all, of these requirements, reach out to the Connext team for more detailed integration tests.","title":"Chain Requirements"},{"location":"router/chains/#contract-testing","text":"If there is any concern about whether your chain supports the required behavior, it is possible to run the full contract test suite against your chain: Add the network information to the hardhat.config.ts . Specifically, include: a funded mnemonic a chainId a provider url Run the test suite using: $ bash ops/test-network.sh <NETWORK_NAME> <CHAIN_PROVIDERS> <FUNDED_MNEMONIC> # i.e. for running against matic: # bash ops/test-network.sh \"matic\" '{ \"80001\" : \"https://rpc-mumbai.matic.today\" }' \"candy maple cake sugar pudding cream honey rich smooth crumble sweet treat\" NOTE These tests are expensive to run, and should be done against a testnet.","title":"Contract Testing"},{"location":"router/chains/#integration-testing","text":"To test a local trio setup against a remote chain: Deploy the contracts to your chain bash ops/deploy-contracts.sh -p <PROVIDER_URL> -m <FUNDED_MNEMONIC> -a <ADDRESS_BOOK_PATH> # the cli inputs are all optional, and if not provided will use the following defaults: # m: \"candy maple cake sugar pudding cream honey rich smooth crumble sweet treat\" # p: \"http://localhost:8545\" # a: \"./address-book.json\" Make sure there is a node.config.json and a router.config.json in the root of your vector directory. If one does not exist run: make config to create files with the preconfigured defaults for a local setup. Update the chainProviders and chainAddresses fields in the node.config.json to include the providers and deployed contract addresses for your network, respectively. Make sure to keep the formatting consistent. See the node configuration section for more information. Update the rebalanceProfiles field in router.config.json to include an entry for the chain with appropriate collateralization values for the native asset. See the router configuration section for more information. Run the trio happy case tests with: make test-trio","title":"Integration Testing"},{"location":"router/configure/","text":"Configuring and Deploying a Routing Vector Node \u00b6 This guide will take you through the e2e process of configuring and deploying a router. Machine Setup \u00b6 Lets say you want to deploy a vector node + router to https://vector.example.com (we'll call this url $DOMAINNAME ). Info If you're planning to launch an instance on your local machine or to a non-Ubuntu OS, you can skip this section and instead install the following dependencies yourself: - make : Probably already installed, otherwise install w brew install make or apt install make or similar. - jq : Probably not installed yet, install w brew install jq or apt install jq or similar. - docker : See the docker website for installation instructions. First step: get a server via AWS or DigitalOcean or setup some hardware at home. For best results, use the most recent LTS version of Ubuntu & make sure it has at least 32GB of disk space. Note this new server's IP address (we'll call this $SERVER_IP ). Make sure it's able to connect to the internet via ports 80, 443, 4221, and 4222 (no action required on DigitalOcean, Security Group config needs to be setup properly on AWS). Set up DNS so that $DOMAINNAME points to $SERVER_IP . If you're using CloudFlare name servers, turn on CloudFlare's built-in SSL support & make sure it's set to \"Full (strict)\". Info If you're just testing things out, you're welcome to skip registering a domain name & instead deploy to a raw IP address. This is a quicker way to get started but isn't recommended for production. In this case, don't turn on CloudFlare's built-in SSL support. We won't need to ssh into this server right away, most of the setup will be done locally. Start by cloning the repo to your local machine if you haven't already and cd into it. git clone git@github.com:connext/vector.git cd vector Every Vector node needs access to a hot wallet, you should generate a fresh mnemonic for your node's wallet that isn't used anywhere else. You can generate a new mnemonic from a node console with ethers by doing something like this: require('ethers').Wallet.createRandom() . Alternatively, you can generate one here . Warning We have a mnemonic hardcoded throughout our repo which is great to use in local testnets: candy maple ... sweet treat . If you try to use this mnemonic on a public testnet, it's possible that someone else is trying to use it at the same time. In the case where two nodes try to use the same mnemonic, vector will fail in unpredictable ways. To avoid encountering hard to debug errors, make sure you are using a private mnemonic that only you know, even on testnets. Save this mnemonic somewhere safe and copy it to your clipboard. From your local machine, run: SSH_KEY = $HOME /.ssh/id_rsa bash ops/server-setup.sh $SERVER_IP Info $HOME/.ssh/id_rsa is the default SSH_KEY , if this is the key you'll use to access $SERVER_IP then you don't need to supply it explicitly The script should automatically do the following tasks to set up the environment: Install all required dependencies. Securely store your mnemonic as a docker secret Clone the Vector repo This script is idempotent which means you can run it over and over again w/out causing any problems. In fact, re-running it every month or so will help keep things up-to-date (you can skip inputting the mnemonic on subsequent runs). For convenience's sake, we recommend adding an entry to your ssh config to easily access this server. Add something that looks like the following to $HOME/.ssh/config : Host new-vector Hostname $SERVER_IP User ubuntu IdentityFile ~/.ssh/id_rsa ServerAliveInterval 120 Now you can login to your new server with just ssh new-vector . Contract Deployment \u00b6 Before moving any further, you should first ensure that the required Vector contracts are deployed to your chain. We have a global address-book in the root of the Vector repo which contains the addresses of deployed contracts indexed by chainId. If you can't find the specific chain(s) that you want to deploy a routing node to, you likely need to deploy contracts first. To deploy contracts, you can use our helper script. (A CLI usable via npx is coming soon!) bash ops/deploy-contracts.sh --eth-provider = \" $ethProvider \" --mnemonic = \" $mnemonic \" Warning Make sure the mnemonic cli argument is wrapped in double quotes to ensure it's all interpreted as one argument In the above command, $mnemonic controls a funded account on whatever chain you plan to deploy to, and $ethProvider is a provider URL for the same chain (e.g. an Infura url including an API key). Any newly deployed contracts will have their addresses added to the project root's address-book.json . Make sure your address-book is stored somewhere safe. The best option would be to submit a PR to our repo so that these addresses are backed up for you and so that they're readily available for everyone else to use too! Info The account that deploys the contracts does not need to be the same one as your vector node's hot wallet. Configuring the Router \u00b6 After setting up dependencies, ssh into the server and enter the Vector repo: ssh new-vector cd vector As we mentioned on the Router Basics page, the router sits on top of a server-node and consumes its gRPC interface. This means that configuring a router is an extension of configuring a normal server-node ! Router Configuration Keys \u00b6 Default router configuration can be found in ops/config/router.default.json . To setup your custom config, start out by copying this file to router.config.json : cp ops/config/router.default.json router.config.json (or you can run make config , a helper that copies all default config files to the project root) The router's node can be configured by adding any of the following keys to router.config.json : Key Type Description chainAddresses object Specifies the addresses of all relevant contracts, keyed by chainId . chainProviders object Specifies the URL to use to connect to each chain's provider, keyed by chainId logLevel string One of \"debug\" , \"info\" , \"warn\" , \"error\" to specify the maximum log level that will be printed. messagingUrl string The url used to connect to the messaging service. This will eventually be defaulted in prod-mode to a global service. port number The port number on which the stack should be exposed to the outside world. allowedSwaps object Specifies which swaps are allowed & how swap rates are determined. rebalanceProfiles object Specifies the thresholds & target while collateralizing some assetId on some chainId . awsAccessId string An API KEY id that specifies credentials for a remote AWS S3 bucket for storing db backups awsAccessKey string An API KEY secret that to authenticate on a remote AWS S3 bucket for storing db backups. domainName string If provided, https will be auto-configured & the stack will be exposed on port 443. production boolean If false , ops will automatically build anything that isn't available locally. If `true, nothing will be built locally. Setting Up Supported Chains \u00b6 To add support for one or many chains on this router, add a chainAddresses and chainProviders key to the router.config.json file in the root of the vector repo: nano router.config.json Recall that you deployed contracts to the chain(s) you want to support earlier in this guide . If you open up your address-book.json , you should find deployed addresses for your chain indexed by chainId . Copy them over into the config file like below. Also, plug in a providerURL into your chainProvider s object indexed at the same chainId. // Example Addresses \"chainAddresses\" : { \"4\" : { \"channelFactoryAddress\" : \"0xF12b5dd4EAD5F743C6BaA640B0216200e89B60Da\" , \"channelMastercopyAddress\" : \"0x8CdaF0CD259887258Bc13a92C0a6dA92698644C0\" , \"transferRegistryAddress\" : \"0x345cA3e014Aaf5dcA488057592ee47305D9B3e10\" , } } , \"chainProviders\" : { \"4\" : \"https://rinkeby.infura.io/abc123\" } , Tip You can support as many evm-compatible chains as you'd like in the above so long as they have a chainId and you have a provider for that chain! Setting Up Supported Assets \u00b6 Routers need to explicitly configure their supported assets. We do this by setting up a rebalanceProfile for each asset we want to support. In order to forward transfers, routers first need to have liquidity (i.e. collateral) in the recipient-side channel to route a transfer over. A rebalanceProfile defines parameters around minimum, maximum, and targete liquidity amounts for a given asset. We cover this in more depth in our Managing Collateral section. An example profile just for Eth looks like the following. Note that we use a combination of chainId and assetId to represent a given asset (where 0x0 is the \"base\" asset of the chain): // E.g. Eth { \"chainId\" : 1 , \"assetId\" : \"0x0000000000000000000000000000000000000000\" , \"reclaimThreshold\" : \"200000000000000000\" , \"target\" : \"100000000000000000\" , \"collateralizeThreshold\" : \"50000000000000000\" } , You can add profiles by setting them under the rebalanceProfile key in your router.config.json : \"rebalanceProfiles\" : [ { \"chainId\" : 1 , \"assetId\" : \"0x0000000000000000000000000000000000000000\" , \"reclaimThreshold\" : \"200000000000000000\" , \"target\" : \"100000000000000000\" , \"collateralizeThreshold\" : \"50000000000000000\" }, { \"chainId\" : 1 , \"assetId\" : \"0x8f0483125FCb9aaAEFA9209D8E9d7b9C8B9Fb90F\" , \"reclaimThreshold\" : \"2000000000000000000\" , \"target\" : \"1000000000000000000\" , \"collateralizeThreshold\" : \"500000000000000000\" }, ] Connext routers also support in-flight swaps when forwarding transfers! In other words, a router can receive a transfer in $ETH and forward it in $DAI so long as an allowedSwap exists for that pair. To allow swapping between the two assets above, you can set the following up under the allowedSwaps key in your router.config.json : \"allowedSwaps\" : [ { \"fromChainId\" : 1 , \"toChainId\" : 1 , \"fromAssetId\" : \"0x0000000000000000000000000000000000000000\" , \"toAssetId\" : \"0x8f0483125FCb9aaAEFA9209D8E9d7b9C8B9Fb90F\" , \"priceType\" : \"hardcoded\" , \"hardcodedRate\" : \"1\" }, { \"fromChainId\" : 1 , \"toChainId\" : 1 , \"fromAssetId\" : \"0x8f0483125FCb9aaAEFA9209D8E9d7b9C8B9Fb90F\" , \"toAssetId\" : \"0x0000000000000000000000000000000000000000\" , \"priceType\" : \"hardcoded\" , \"hardcodedRate\" : \"1\" } ] , Tip Above, we're setting default values for rebalance profiles and allowed swaps. In reality, these values (especially swap rates) likely need to be continuously updated at runtime every time period and/or on a per-channel basis. We go over how to plug in data sources for rates and profiles in our Managing Collateral section. Spinning Up the Router \u00b6 Now that we have our configuration complete, we can spin up the router! This part is pretty easy - in the root of the vector repo, do: make restart-router Tip make start-$STACK is optimized for development & will build everything that's out of date before starting the stack. make restart-$STACK on the other hand, won't try to build anything before starting the stack so is better to use in production.","title":"Configuring and Deploying a Routing Vector Node"},{"location":"router/configure/#configuring-and-deploying-a-routing-vector-node","text":"This guide will take you through the e2e process of configuring and deploying a router.","title":"Configuring and Deploying a Routing Vector Node"},{"location":"router/configure/#machine-setup","text":"Lets say you want to deploy a vector node + router to https://vector.example.com (we'll call this url $DOMAINNAME ). Info If you're planning to launch an instance on your local machine or to a non-Ubuntu OS, you can skip this section and instead install the following dependencies yourself: - make : Probably already installed, otherwise install w brew install make or apt install make or similar. - jq : Probably not installed yet, install w brew install jq or apt install jq or similar. - docker : See the docker website for installation instructions. First step: get a server via AWS or DigitalOcean or setup some hardware at home. For best results, use the most recent LTS version of Ubuntu & make sure it has at least 32GB of disk space. Note this new server's IP address (we'll call this $SERVER_IP ). Make sure it's able to connect to the internet via ports 80, 443, 4221, and 4222 (no action required on DigitalOcean, Security Group config needs to be setup properly on AWS). Set up DNS so that $DOMAINNAME points to $SERVER_IP . If you're using CloudFlare name servers, turn on CloudFlare's built-in SSL support & make sure it's set to \"Full (strict)\". Info If you're just testing things out, you're welcome to skip registering a domain name & instead deploy to a raw IP address. This is a quicker way to get started but isn't recommended for production. In this case, don't turn on CloudFlare's built-in SSL support. We won't need to ssh into this server right away, most of the setup will be done locally. Start by cloning the repo to your local machine if you haven't already and cd into it. git clone git@github.com:connext/vector.git cd vector Every Vector node needs access to a hot wallet, you should generate a fresh mnemonic for your node's wallet that isn't used anywhere else. You can generate a new mnemonic from a node console with ethers by doing something like this: require('ethers').Wallet.createRandom() . Alternatively, you can generate one here . Warning We have a mnemonic hardcoded throughout our repo which is great to use in local testnets: candy maple ... sweet treat . If you try to use this mnemonic on a public testnet, it's possible that someone else is trying to use it at the same time. In the case where two nodes try to use the same mnemonic, vector will fail in unpredictable ways. To avoid encountering hard to debug errors, make sure you are using a private mnemonic that only you know, even on testnets. Save this mnemonic somewhere safe and copy it to your clipboard. From your local machine, run: SSH_KEY = $HOME /.ssh/id_rsa bash ops/server-setup.sh $SERVER_IP Info $HOME/.ssh/id_rsa is the default SSH_KEY , if this is the key you'll use to access $SERVER_IP then you don't need to supply it explicitly The script should automatically do the following tasks to set up the environment: Install all required dependencies. Securely store your mnemonic as a docker secret Clone the Vector repo This script is idempotent which means you can run it over and over again w/out causing any problems. In fact, re-running it every month or so will help keep things up-to-date (you can skip inputting the mnemonic on subsequent runs). For convenience's sake, we recommend adding an entry to your ssh config to easily access this server. Add something that looks like the following to $HOME/.ssh/config : Host new-vector Hostname $SERVER_IP User ubuntu IdentityFile ~/.ssh/id_rsa ServerAliveInterval 120 Now you can login to your new server with just ssh new-vector .","title":"Machine Setup"},{"location":"router/configure/#contract-deployment","text":"Before moving any further, you should first ensure that the required Vector contracts are deployed to your chain. We have a global address-book in the root of the Vector repo which contains the addresses of deployed contracts indexed by chainId. If you can't find the specific chain(s) that you want to deploy a routing node to, you likely need to deploy contracts first. To deploy contracts, you can use our helper script. (A CLI usable via npx is coming soon!) bash ops/deploy-contracts.sh --eth-provider = \" $ethProvider \" --mnemonic = \" $mnemonic \" Warning Make sure the mnemonic cli argument is wrapped in double quotes to ensure it's all interpreted as one argument In the above command, $mnemonic controls a funded account on whatever chain you plan to deploy to, and $ethProvider is a provider URL for the same chain (e.g. an Infura url including an API key). Any newly deployed contracts will have their addresses added to the project root's address-book.json . Make sure your address-book is stored somewhere safe. The best option would be to submit a PR to our repo so that these addresses are backed up for you and so that they're readily available for everyone else to use too! Info The account that deploys the contracts does not need to be the same one as your vector node's hot wallet.","title":"Contract Deployment"},{"location":"router/configure/#configuring-the-router","text":"After setting up dependencies, ssh into the server and enter the Vector repo: ssh new-vector cd vector As we mentioned on the Router Basics page, the router sits on top of a server-node and consumes its gRPC interface. This means that configuring a router is an extension of configuring a normal server-node !","title":"Configuring the Router"},{"location":"router/configure/#router-configuration-keys","text":"Default router configuration can be found in ops/config/router.default.json . To setup your custom config, start out by copying this file to router.config.json : cp ops/config/router.default.json router.config.json (or you can run make config , a helper that copies all default config files to the project root) The router's node can be configured by adding any of the following keys to router.config.json : Key Type Description chainAddresses object Specifies the addresses of all relevant contracts, keyed by chainId . chainProviders object Specifies the URL to use to connect to each chain's provider, keyed by chainId logLevel string One of \"debug\" , \"info\" , \"warn\" , \"error\" to specify the maximum log level that will be printed. messagingUrl string The url used to connect to the messaging service. This will eventually be defaulted in prod-mode to a global service. port number The port number on which the stack should be exposed to the outside world. allowedSwaps object Specifies which swaps are allowed & how swap rates are determined. rebalanceProfiles object Specifies the thresholds & target while collateralizing some assetId on some chainId . awsAccessId string An API KEY id that specifies credentials for a remote AWS S3 bucket for storing db backups awsAccessKey string An API KEY secret that to authenticate on a remote AWS S3 bucket for storing db backups. domainName string If provided, https will be auto-configured & the stack will be exposed on port 443. production boolean If false , ops will automatically build anything that isn't available locally. If `true, nothing will be built locally.","title":"Router Configuration Keys"},{"location":"router/configure/#setting-up-supported-chains","text":"To add support for one or many chains on this router, add a chainAddresses and chainProviders key to the router.config.json file in the root of the vector repo: nano router.config.json Recall that you deployed contracts to the chain(s) you want to support earlier in this guide . If you open up your address-book.json , you should find deployed addresses for your chain indexed by chainId . Copy them over into the config file like below. Also, plug in a providerURL into your chainProvider s object indexed at the same chainId. // Example Addresses \"chainAddresses\" : { \"4\" : { \"channelFactoryAddress\" : \"0xF12b5dd4EAD5F743C6BaA640B0216200e89B60Da\" , \"channelMastercopyAddress\" : \"0x8CdaF0CD259887258Bc13a92C0a6dA92698644C0\" , \"transferRegistryAddress\" : \"0x345cA3e014Aaf5dcA488057592ee47305D9B3e10\" , } } , \"chainProviders\" : { \"4\" : \"https://rinkeby.infura.io/abc123\" } , Tip You can support as many evm-compatible chains as you'd like in the above so long as they have a chainId and you have a provider for that chain!","title":"Setting Up Supported Chains"},{"location":"router/configure/#setting-up-supported-assets","text":"Routers need to explicitly configure their supported assets. We do this by setting up a rebalanceProfile for each asset we want to support. In order to forward transfers, routers first need to have liquidity (i.e. collateral) in the recipient-side channel to route a transfer over. A rebalanceProfile defines parameters around minimum, maximum, and targete liquidity amounts for a given asset. We cover this in more depth in our Managing Collateral section. An example profile just for Eth looks like the following. Note that we use a combination of chainId and assetId to represent a given asset (where 0x0 is the \"base\" asset of the chain): // E.g. Eth { \"chainId\" : 1 , \"assetId\" : \"0x0000000000000000000000000000000000000000\" , \"reclaimThreshold\" : \"200000000000000000\" , \"target\" : \"100000000000000000\" , \"collateralizeThreshold\" : \"50000000000000000\" } , You can add profiles by setting them under the rebalanceProfile key in your router.config.json : \"rebalanceProfiles\" : [ { \"chainId\" : 1 , \"assetId\" : \"0x0000000000000000000000000000000000000000\" , \"reclaimThreshold\" : \"200000000000000000\" , \"target\" : \"100000000000000000\" , \"collateralizeThreshold\" : \"50000000000000000\" }, { \"chainId\" : 1 , \"assetId\" : \"0x8f0483125FCb9aaAEFA9209D8E9d7b9C8B9Fb90F\" , \"reclaimThreshold\" : \"2000000000000000000\" , \"target\" : \"1000000000000000000\" , \"collateralizeThreshold\" : \"500000000000000000\" }, ] Connext routers also support in-flight swaps when forwarding transfers! In other words, a router can receive a transfer in $ETH and forward it in $DAI so long as an allowedSwap exists for that pair. To allow swapping between the two assets above, you can set the following up under the allowedSwaps key in your router.config.json : \"allowedSwaps\" : [ { \"fromChainId\" : 1 , \"toChainId\" : 1 , \"fromAssetId\" : \"0x0000000000000000000000000000000000000000\" , \"toAssetId\" : \"0x8f0483125FCb9aaAEFA9209D8E9d7b9C8B9Fb90F\" , \"priceType\" : \"hardcoded\" , \"hardcodedRate\" : \"1\" }, { \"fromChainId\" : 1 , \"toChainId\" : 1 , \"fromAssetId\" : \"0x8f0483125FCb9aaAEFA9209D8E9d7b9C8B9Fb90F\" , \"toAssetId\" : \"0x0000000000000000000000000000000000000000\" , \"priceType\" : \"hardcoded\" , \"hardcodedRate\" : \"1\" } ] , Tip Above, we're setting default values for rebalance profiles and allowed swaps. In reality, these values (especially swap rates) likely need to be continuously updated at runtime every time period and/or on a per-channel basis. We go over how to plug in data sources for rates and profiles in our Managing Collateral section.","title":"Setting Up Supported Assets"},{"location":"router/configure/#spinning-up-the-router","text":"Now that we have our configuration complete, we can spin up the router! This part is pretty easy - in the root of the vector repo, do: make restart-router Tip make start-$STACK is optimized for development & will build everything that's out of date before starting the stack. make restart-$STACK on the other hand, won't try to build anything before starting the stack so is better to use in production.","title":"Spinning Up the Router"}]}